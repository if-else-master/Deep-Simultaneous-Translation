import pyaudio
import wave
import threading
import time
import io
import google.generativeai as genai
from TTS.tts.configs.xtts_config import XttsConfig
from TTS.tts.models.xtts import Xtts
import torch
import scipy.io.wavfile
import numpy as np
import pygame
import tempfile
import os
import shutil
import queue
from collections import deque
import getpass
import tkinter as tk
from tkinter import ttk, messagebox, filedialog, scrolledtext
import glob
from datetime import datetime

def setup_mecab():
    """è¨­ç½® MeCab é…ç½®ä»¥æ”¯æŒæ—¥èªè™•ç†"""
    try:
        import unidic_lite
        dicdir = unidic_lite.dicdir
        mecabrc_path = os.path.join(dicdir, 'mecabrc')
        if os.path.exists(mecabrc_path):
            os.environ['MECABRC'] = mecabrc_path
            print("âœ… ä½¿ç”¨ unidic-lite è©å…¸")
            return True
        else:
            print("âœ… unidic-lite å¯ç”¨ï¼Œä½¿ç”¨é è¨­é…ç½®")
            return True
    except (ImportError, AttributeError):
        pass
    possible_paths = [
        '/opt/homebrew/etc/mecabrc',  # Homebrew Apple Silicon
        '/usr/local/etc/mecabrc',     # Homebrew Intel
        '/usr/etc/mecabrc',           # ç³»çµ±å®‰è£
    ]
    
    for path in possible_paths:
        if os.path.exists(path):
            os.environ['MECABRC'] = path
            print(f"âœ… ä½¿ç”¨ç³»çµ± MeCab é…ç½®: {path}")
            return True
    
    print("âš ï¸ æœªæ‰¾åˆ° MeCab é…ç½®ï¼Œæ—¥èªè™•ç†å¯èƒ½å—é™")
    return False

# åˆå§‹åŒ– MeCab é…ç½®
mecab_available = setup_mecab()

class VoiceTranslationGUI:
    def __init__(self):
        # å‰µå»ºä¸»çª—å£
        self.root = tk.Tk()
        self.root.title("ğŸ¤ å³æ™‚èªéŸ³å…‹éš†ç¿»è­¯ç³»çµ±")
        self.root.geometry("1200x900")
        self.root.configure(bg='#2c3e50')
        self.root.minsize(800, 600)
        
        # ç³»çµ±å¾Œç«¯
        self.backend = RealTimeVoiceTranslationSystem()
        
        # GUI ç‹€æ…‹
        self.is_recording = False
        self.recording_animation_id = None
        
        # å‰µå»ºç•Œé¢
        self.create_widgets()
        
        # è¨­ç½®æŒ‰éˆ•æ‡¸åœæ•ˆæœ
        self.setup_hover_effects()
        
        # è¼‰å…¥å·²å­˜åœ¨çš„èªéŸ³æ–‡ä»¶
        self.load_existing_voices()
        
    def create_widgets(self):
        """å‰µå»ºæ‰€æœ‰GUIå…ƒä»¶"""
        # æ·±è‰²ä¸»é¡Œé…è‰²
        self.colors = {
            'bg_primary': '#2c3e50',      # ä¸»èƒŒæ™¯ - æ·±è—ç°
            'bg_secondary': '#34495e',     # æ¬¡è¦èƒŒæ™¯ - è—ç°
            'bg_card': '#3c4043',         # å¡ç‰‡èƒŒæ™¯ - æ·±ç°
            'text_primary': '#ecf0f1',    # ä¸»æ–‡å­— - æ·ºç°ç™½
            'text_secondary': '#bdc3c7',  # æ¬¡è¦æ–‡å­— - ç°è‰²
            'accent_blue': '#3498db',     # è—è‰²å¼·èª¿
            'accent_green': '#27ae60',    # ç¶ è‰²å¼·èª¿
            'accent_orange': '#f39c12',   # æ©™è‰²å¼·èª¿
            'accent_red': '#e74c3c',      # ç´…è‰²å¼·èª¿
            'input_bg': '#2c3e50',        # è¼¸å…¥æ¡†èƒŒæ™¯
            'input_text': '#ecf0f1',      # è¼¸å…¥æ¡†æ–‡å­—
            'button_bg': '#3c4043',       # æŒ‰éˆ•èƒŒæ™¯ - æ·±ç°
            'button_hover': '#4a4a4a'     # æŒ‰éˆ•æ‡¸åœ - æ›´æ·±çš„ç°
        }
        
        # æ¨™é¡Œ
        title_frame = tk.Frame(self.root, bg=self.colors['bg_primary'])
        title_frame.pack(pady=15)
        
        title_label = tk.Label(title_frame, text="ğŸ¤ å³æ™‚èªéŸ³å…‹éš†ç¿»è­¯ç³»çµ±", 
                              font=('SF Pro Display', 24, 'bold'), 
                              bg=self.colors['bg_primary'], 
                              fg=self.colors['text_primary'])
        title_label.pack()
        
        subtitle_label = tk.Label(title_frame, text="Deep Simultaneous Translation", 
                                 font=('SF Pro Display', 12), 
                                 bg=self.colors['bg_primary'], 
                                 fg=self.colors['text_secondary'])
        subtitle_label.pack(pady=(5, 0))
        
        # API Key è¨­ç½®å€åŸŸ
        api_frame = tk.LabelFrame(self.root, text="ğŸ“¡ API è¨­ç½®", 
                                 font=('SF Pro Display', 14, 'bold'), 
                                 bg=self.colors['bg_secondary'], 
                                 fg=self.colors['text_primary'],
                                 bd=2, relief='groove',
                                 padx=15, pady=15)
        api_frame.pack(fill='x', padx=25, pady=8)
        
        tk.Label(api_frame, text="Gemini API Key:", 
                bg=self.colors['bg_secondary'], 
                fg=self.colors['text_primary'],
                font=('SF Pro Display', 11)).grid(row=0, column=0, sticky='w', pady=5)
        
        self.api_key_entry = tk.Entry(api_frame, width=55, show='*', 
                                     font=('SF Pro Display', 11),
                                     bg=self.colors['input_bg'], 
                                     fg=self.colors['input_text'],
                                     insertbackground=self.colors['text_primary'],
                                     bd=2, relief='solid')
        self.api_key_entry.grid(row=0, column=1, padx=10, sticky='w')
        
        self.test_api_btn = tk.Button(api_frame, text="âœ… æ¸¬è©¦ API", command=self.test_api,
                                     bg=self.colors['button_bg'], fg='black', 
                                     font=('SF Pro Display', 11, 'bold'),
                                     bd=0, relief='flat', cursor='hand2',
                                     padx=15, pady=8)
        self.test_api_btn.grid(row=0, column=2, padx=10)
        
        # èªè¨€è¨­ç½®å€åŸŸ
        lang_frame = tk.LabelFrame(self.root, text="ğŸŒ èªè¨€è¨­ç½®", 
                                  font=('SF Pro Display', 14, 'bold'), 
                                  bg=self.colors['bg_secondary'], 
                                  fg=self.colors['text_primary'],
                                  bd=2, relief='groove',
                                  padx=15, pady=15)
        lang_frame.pack(fill='x', padx=25, pady=8)
        
        # èªè¨€é¸é …
        languages = {
            'zh': 'ä¸­æ–‡', 'en': 'è‹±æ–‡', 'ja': 'æ—¥æ–‡', 'ko': 'éŸ“æ–‡',
            'es': 'è¥¿ç­ç‰™æ–‡', 'fr': 'æ³•æ–‡', 'de': 'å¾·æ–‡', 'it': 'æ„å¤§åˆ©æ–‡', 'pt': 'è‘¡è„ç‰™æ–‡'
        }
        
        tk.Label(lang_frame, text="åŸå§‹èªè¨€:", 
                bg=self.colors['bg_secondary'], 
                fg=self.colors['text_primary'],
                font=('SF Pro Display', 11)).grid(row=0, column=0, sticky='w', pady=5)
        
        self.source_lang_var = tk.StringVar(value='zh')
        
        # å‰µå»ºè‡ªå®šç¾©æ¨£å¼çš„ Combobox
        style = ttk.Style()
        style.theme_use('clam')
        style.configure('Custom.TCombobox',
                       fieldbackground=self.colors['input_bg'],
                       background=self.colors['bg_secondary'],
                       foreground=self.colors['text_primary'],
                       arrowcolor=self.colors['text_primary'],
                       bordercolor=self.colors['accent_blue'],
                       lightcolor=self.colors['bg_secondary'],
                       darkcolor=self.colors['bg_secondary'])
        
        self.source_lang_combo = ttk.Combobox(lang_frame, textvariable=self.source_lang_var, 
                                             values=list(languages.keys()), state='readonly', 
                                             width=12, style='Custom.TCombobox',
                                             font=('SF Pro Display', 11))
        self.source_lang_combo.grid(row=0, column=1, padx=10)
        
        tk.Label(lang_frame, text="ç›®æ¨™èªè¨€:", 
                bg=self.colors['bg_secondary'], 
                fg=self.colors['text_primary'],
                font=('SF Pro Display', 11)).grid(row=0, column=2, sticky='w', padx=(25,5))
        
        self.target_lang_var = tk.StringVar(value='en')
        self.target_lang_combo = ttk.Combobox(lang_frame, textvariable=self.target_lang_var, 
                                             values=list(languages.keys()), state='readonly', 
                                             width=12, style='Custom.TCombobox',
                                             font=('SF Pro Display', 11))
        self.target_lang_combo.grid(row=0, column=3, padx=10)
        
        # èªéŸ³å…‹éš†å€åŸŸ
        voice_frame = tk.LabelFrame(self.root, text="ğŸ­ èªéŸ³å…‹éš†", 
                                   font=('SF Pro Display', 14, 'bold'), 
                                   bg=self.colors['bg_secondary'], 
                                   fg=self.colors['text_primary'],
                                   bd=2, relief='groove',
                                   padx=15, pady=15)
        voice_frame.pack(fill='x', padx=25, pady=8)
        
        # èªéŸ³é¸æ“‡
        tk.Label(voice_frame, text="é¸æ“‡èªéŸ³:", 
                bg=self.colors['bg_secondary'], 
                fg=self.colors['text_primary'],
                font=('SF Pro Display', 11)).grid(row=0, column=0, sticky='w', pady=5)
        
        self.voice_var = tk.StringVar()
        self.voice_combo = ttk.Combobox(voice_frame, textvariable=self.voice_var, 
                                       state='readonly', width=35, 
                                       style='Custom.TCombobox',
                                       font=('SF Pro Display', 11))
        self.voice_combo.grid(row=0, column=1, padx=10, sticky='w')
        
        # èªéŸ³å…‹éš†æŒ‰éˆ•
        self.clone_voice_btn = tk.Button(voice_frame, text="ğŸ¤ éŒ„è£½æ–°èªéŸ³", command=self.clone_voice,
                                        bg=self.colors['button_bg'], fg='black', 
                                        font=('SF Pro Display', 11, 'bold'),
                                        bd=0, relief='flat', cursor='hand2',
                                        padx=15, pady=8)
        self.clone_voice_btn.grid(row=0, column=2, padx=12)
        
        self.load_model_btn = tk.Button(voice_frame, text="ğŸ¤– è¼‰å…¥æ¨¡å‹", command=self.load_xtts_model,
                                       bg=self.colors['button_bg'], fg='black', 
                                       font=('SF Pro Display', 11, 'bold'),
                                       bd=0, relief='flat', cursor='hand2',
                                       padx=15, pady=8)
        self.load_model_btn.grid(row=0, column=3, padx=8)
        
        # é€å­—ç¨¿é¡¯ç¤ºå€åŸŸ
        transcript_frame = tk.Frame(self.root, bg=self.colors['bg_primary'])
        transcript_frame.pack(fill='both', expand=True, padx=25, pady=15)
        
        # åŸæ–‡é€å­—ç¨¿
        original_label_frame = tk.Frame(transcript_frame, bg=self.colors['bg_primary'])
        original_label_frame.pack(fill='x', pady=(0, 5))
        
        tk.Label(original_label_frame, text="ğŸ“ åŸæ–‡é€å­—ç¨¿", 
                bg=self.colors['bg_primary'], 
                fg=self.colors['text_primary'],
                font=('SF Pro Display', 14, 'bold')).pack(side='left')
        
        tk.Label(original_label_frame, text="Real-time Speech Recognition", 
                bg=self.colors['bg_primary'], 
                fg=self.colors['text_secondary'],
                font=('SF Pro Display', 10)).pack(side='right')
        
        self.original_text = scrolledtext.ScrolledText(transcript_frame, height=9, wrap=tk.WORD,
                                                      font=('SF Pro Display', 12), 
                                                      bg=self.colors['bg_card'], 
                                                      fg=self.colors['text_primary'],
                                                      insertbackground=self.colors['text_primary'],
                                                      selectbackground=self.colors['accent_blue'],
                                                      selectforeground='white',
                                                      bd=2, relief='solid')
        self.original_text.pack(fill='both', expand=True, pady=(0, 15))
        
        # ç¿»è­¯é€å­—ç¨¿
        translated_label_frame = tk.Frame(transcript_frame, bg=self.colors['bg_primary'])
        translated_label_frame.pack(fill='x', pady=(0, 5))
        
        tk.Label(translated_label_frame, text="ğŸŒ ç¿»è­¯é€å­—ç¨¿", 
                bg=self.colors['bg_primary'], 
                fg=self.colors['text_primary'],
                font=('SF Pro Display', 14, 'bold')).pack(side='left')
        
        tk.Label(translated_label_frame, text="Real-time Translation", 
                bg=self.colors['bg_primary'], 
                fg=self.colors['text_secondary'],
                font=('SF Pro Display', 10)).pack(side='right')
        
        self.translated_text = scrolledtext.ScrolledText(transcript_frame, height=9, wrap=tk.WORD,
                                                        font=('SF Pro Display', 12), 
                                                        bg=self.colors['bg_card'], 
                                                        fg=self.colors['accent_green'],
                                                        insertbackground=self.colors['accent_green'],
                                                        selectbackground=self.colors['accent_green'],
                                                        selectforeground='white',
                                                        bd=2, relief='solid')
        self.translated_text.pack(fill='both', expand=True, pady=(0, 15))
        
        # æ§åˆ¶å€åŸŸ
        control_frame = tk.Frame(self.root, bg=self.colors['bg_secondary'], relief='groove', bd=2)
        control_frame.pack(fill='x', padx=25, pady=(0, 20))
        
        # å…§éƒ¨æ§åˆ¶æ¡†æ¶
        inner_control = tk.Frame(control_frame, bg=self.colors['bg_secondary'])
        inner_control.pack(fill='x', padx=20, pady=15)
        
        # èªéŸ³è¼¸å‡ºæ§åˆ¶
        self.enable_voice_var = tk.BooleanVar(value=True)
        self.enable_voice_check = tk.Checkbutton(inner_control, text="ğŸ”Š å•Ÿç”¨èªéŸ³è¼¸å‡º", 
                                                variable=self.enable_voice_var, 
                                                bg=self.colors['bg_secondary'],
                                                fg=self.colors['text_primary'],
                                                selectcolor=self.colors['bg_card'],
                                                activebackground=self.colors['bg_secondary'],
                                                activeforeground=self.colors['text_primary'],
                                                font=('SF Pro Display', 12), 
                                                cursor='hand2')
        self.enable_voice_check.pack(side='left')
        
        # ç‹€æ…‹é¡¯ç¤º
        self.status_label = tk.Label(inner_control, text="ğŸ“‹ ç³»çµ±å°±ç·’", 
                                    bg=self.colors['bg_secondary'], 
                                    fg=self.colors['text_secondary'],
                                    font=('SF Pro Display', 12))
        self.status_label.pack(side='left', padx=30)
        
        # é–‹å§‹ç¿»è­¯æŒ‰éˆ•
        self.start_btn = tk.Button(inner_control, text="ğŸš€ é–‹å§‹å³æ™‚ç¿»è­¯", command=self.toggle_translation,
                                  bg=self.colors['button_bg'], fg='black', 
                                  font=('SF Pro Display', 16, 'bold'),
                                  bd=0, relief='flat', cursor='hand2',
                                  padx=25, pady=12)
        self.start_btn.pack(side='right')
    
    def setup_hover_effects(self):
        """è¨­ç½®æŒ‰éˆ•æ‡¸åœæ•ˆæœ"""
        def on_enter(event, original_bg, hover_bg):
            event.widget.config(bg=hover_bg)
        
        def on_leave(event, original_bg, hover_bg):
            event.widget.config(bg=original_bg)
        
        # API æ¸¬è©¦æŒ‰éˆ•æ‡¸åœæ•ˆæœ
        self.test_api_btn.bind("<Enter>", lambda e: on_enter(e, self.colors['button_bg'], self.colors['button_hover']))
        self.test_api_btn.bind("<Leave>", lambda e: on_leave(e, self.colors['button_bg'], self.colors['button_hover']))
        
        # èªéŸ³å…‹éš†æŒ‰éˆ•æ‡¸åœæ•ˆæœ
        self.clone_voice_btn.bind("<Enter>", lambda e: on_enter(e, self.colors['button_bg'], self.colors['button_hover']))
        self.clone_voice_btn.bind("<Leave>", lambda e: on_leave(e, self.colors['button_bg'], self.colors['button_hover']))
        
        # è¼‰å…¥æ¨¡å‹æŒ‰éˆ•æ‡¸åœæ•ˆæœ
        self.load_model_btn.bind("<Enter>", lambda e: on_enter(e, self.colors['button_bg'], self.colors['button_hover']))
        self.load_model_btn.bind("<Leave>", lambda e: on_leave(e, self.colors['button_bg'], self.colors['button_hover']))
        
        # é–‹å§‹ç¿»è­¯æŒ‰éˆ•æ‡¸åœæ•ˆæœ
        self.start_btn.bind("<Enter>", lambda e: on_enter(e, self.colors['button_bg'], self.colors['button_hover']))
        self.start_btn.bind("<Leave>", lambda e: on_leave(e, self.colors['button_bg'], self.colors['button_hover']))
        
    def load_existing_voices(self):
        """è¼‰å…¥å·²å­˜åœ¨çš„èªéŸ³æ–‡ä»¶"""
        try:
            if not os.path.exists("cloned_voices"):
                os.makedirs("cloned_voices")
            
            voice_files = glob.glob("cloned_voices/*.wav")
            voice_names = [os.path.basename(f) for f in voice_files]
            
            if voice_names:
                self.voice_combo['values'] = voice_names
                self.voice_combo.set(voice_names[0])
                self.backend.cloned_voice_path = os.path.join("cloned_voices", voice_names[0])
                self.backend.is_voice_cloned = True
                self.update_status("âœ… å·²è¼‰å…¥èªéŸ³æ–‡ä»¶")
            else:
                self.voice_combo['values'] = ["ç„¡å¯ç”¨èªéŸ³"]
                self.update_status("âš ï¸ è«‹å…ˆéŒ„è£½èªéŸ³")
                
        except Exception as e:
            self.update_status(f"âŒ è¼‰å…¥èªéŸ³å¤±æ•—: {e}")
    
    def test_api(self):
        """æ¸¬è©¦ API Key"""
        api_key = self.api_key_entry.get().strip()
        if not api_key:
            messagebox.showerror("éŒ¯èª¤", "è«‹è¼¸å…¥ API Key")
            return
        
        try:
            self.update_status("ğŸ”„ æ¸¬è©¦ API Key...")
            genai.configure(api_key=api_key)
            test_model = genai.GenerativeModel('gemini-2.0-flash-exp')
            test_response = test_model.generate_content("æ¸¬è©¦")
            
            self.backend.gemini_api_key = api_key
            self.backend.model = test_model
            self.update_status("âœ… API Key æœ‰æ•ˆï¼")
            messagebox.showinfo("æˆåŠŸ", "API Key æ¸¬è©¦æˆåŠŸï¼")
            
        except Exception as e:
            self.update_status("âŒ API Key ç„¡æ•ˆ")
            messagebox.showerror("éŒ¯èª¤", f"API Key ç„¡æ•ˆ: {e}")
    
    def clone_voice(self):
        """èªéŸ³å…‹éš†åŠŸèƒ½"""
        if not self.backend.gemini_api_key:
            messagebox.showerror("éŒ¯èª¤", "è«‹å…ˆè¨­ç½®ä¸¦æ¸¬è©¦ API Key")
            return
        
        # å‰µå»ºéŒ„éŸ³å°è©±æ¡†
        self.show_recording_dialog()
    
    def show_recording_dialog(self):
        """é¡¯ç¤ºéŒ„éŸ³å°è©±æ¡†"""
        dialog = tk.Toplevel(self.root)
        dialog.title("ğŸ¤ èªéŸ³éŒ„è£½")
        dialog.geometry("480x280")
        dialog.configure(bg=self.colors['bg_primary'])
        dialog.transient(self.root)
        dialog.grab_set()
        dialog.resizable(False, False)
        
        # å±…ä¸­é¡¯ç¤º
        dialog.update_idletasks()
        x = (dialog.winfo_screenwidth() // 2) - (dialog.winfo_width() // 2)
        y = (dialog.winfo_screenheight() // 2) - (dialog.winfo_height() // 2)
        dialog.geometry(f"+{x}+{y}")
        
        # ä¸»æ¨™é¡Œ
        tk.Label(dialog, text="ğŸ­ èªéŸ³å…‹éš†éŒ„è£½", 
                font=('SF Pro Display', 18, 'bold'), 
                bg=self.colors['bg_primary'], 
                fg=self.colors['text_primary']).pack(pady=25)
        
        # èªªæ˜æ–‡å­—
        instruction = tk.Label(dialog, text="è«‹ç”¨è‡ªç„¶èªèª¿èªªä¸€æ®µè©±ï¼ˆå»ºè­°3-5ç§’ï¼‰\néŒ„éŸ³å°‡åœ¨æ‚¨åœæ­¢èªªè©±2ç§’å¾Œè‡ªå‹•çµæŸ", 
                              font=('SF Pro Display', 12), 
                              bg=self.colors['bg_primary'], 
                              fg=self.colors['text_secondary'], 
                              justify='center')
        instruction.pack(pady=15)
        
        # éŒ„éŸ³ç‹€æ…‹é¡¯ç¤º
        self.recording_status = tk.Label(dialog, text="æº–å‚™éŒ„éŸ³...", 
                                        font=('SF Pro Display', 14, 'bold'), 
                                        bg=self.colors['bg_primary'], 
                                        fg=self.colors['accent_orange'])
        self.recording_status.pack(pady=20)
        
        # æŒ‰éˆ•æ¡†æ¶
        btn_frame = tk.Frame(dialog, bg=self.colors['bg_primary'])
        btn_frame.pack(pady=25)
        
        start_record_btn = tk.Button(btn_frame, text="ğŸ¤ é–‹å§‹éŒ„éŸ³", 
                                    command=lambda: self.start_recording(dialog),
                                    bg=self.colors['button_bg'], fg='black', 
                                    font=('SF Pro Display', 12, 'bold'), 
                                    bd=0, relief='flat', cursor='hand2',
                                    padx=25, pady=10)
        start_record_btn.pack(side='left', padx=15)
        
        cancel_btn = tk.Button(btn_frame, text="âŒ å–æ¶ˆ", command=dialog.destroy,
                              bg=self.colors['button_bg'], fg='white', 
                              font=('SF Pro Display', 12, 'bold'),
                              bd=0, relief='flat', cursor='hand2',
                              padx=25, pady=10)
        cancel_btn.pack(side='left', padx=15)
    
    def start_recording(self, dialog):
        """é–‹å§‹éŒ„éŸ³"""
        try:
            self.recording_status.config(text="ğŸ¤ æ­£åœ¨éŒ„éŸ³...", fg=self.colors['accent_red'])
            dialog.update()
            
            # åŸ·è¡ŒéŒ„éŸ³
            result = self.backend.clone_voice_step_gui()
            
            if result:
                self.recording_status.config(text="âœ… éŒ„éŸ³å®Œæˆï¼", fg=self.colors['accent_green'])
                dialog.update()
                time.sleep(1)
                dialog.destroy()
                
                # é‡æ–°è¼‰å…¥èªéŸ³åˆ—è¡¨
                self.load_existing_voices()
                messagebox.showinfo("æˆåŠŸ", "èªéŸ³å…‹éš†å®Œæˆï¼")
            else:
                self.recording_status.config(text="âŒ éŒ„éŸ³å¤±æ•—", fg=self.colors['accent_red'])
                
        except Exception as e:
            self.recording_status.config(text="âŒ éŒ„éŸ³å¤±æ•—", fg=self.colors['accent_red'])
            messagebox.showerror("éŒ¯èª¤", f"éŒ„éŸ³å¤±æ•—: {e}")
    
    def load_xtts_model(self):
        """è¼‰å…¥ XTTS æ¨¡å‹"""
        try:
            self.update_status("ğŸ”„ è¼‰å…¥ XTTS æ¨¡å‹...")
            self.load_model_btn.config(state='disabled', text="è¼‰å…¥ä¸­...")
            
            # åœ¨å­ç·šç¨‹ä¸­è¼‰å…¥æ¨¡å‹
            thread = threading.Thread(target=self._load_model_thread)
            thread.daemon = True
            thread.start()
            
        except Exception as e:
            self.update_status(f"âŒ è¼‰å…¥æ¨¡å‹å¤±æ•—: {e}")
            self.load_model_btn.config(state='normal', text="ğŸ¤– è¼‰å…¥æ¨¡å‹", bg=self.colors['button_bg'])
    
    def _load_model_thread(self):
        """æ¨¡å‹è¼‰å…¥ç·šç¨‹"""
        try:
            success = self.backend.load_xtts_model()
            
            # æ›´æ–° GUIï¼ˆå¿…é ˆåœ¨ä¸»ç·šç¨‹ä¸­ï¼‰
            self.root.after(0, self._model_loaded_callback, success)
            
        except Exception as e:
            self.root.after(0, self._model_loaded_callback, False, str(e))
    
    def _model_loaded_callback(self, success, error=None):
        """æ¨¡å‹è¼‰å…¥å®Œæˆå›èª¿"""
        if success:
            self.update_status("âœ… XTTS æ¨¡å‹è¼‰å…¥æˆåŠŸï¼")
            self.load_model_btn.config(state='normal', text="âœ… æ¨¡å‹å·²è¼‰å…¥", bg=self.colors['button_bg'])
        else:
            self.update_status(f"âŒ è¼‰å…¥æ¨¡å‹å¤±æ•—: {error or 'æœªçŸ¥éŒ¯èª¤'}")
            self.load_model_btn.config(state='normal', text="ğŸ¤– è¼‰å…¥æ¨¡å‹", bg=self.colors['button_bg'])
    
    def toggle_translation(self):
        """åˆ‡æ›ç¿»è­¯ç‹€æ…‹"""
        if not self.is_recording:
            self.start_translation()
        else:
            self.stop_translation()
    
    def start_translation(self):
        """é–‹å§‹å³æ™‚ç¿»è­¯"""
        # æª¢æŸ¥å¿…è¦æ¢ä»¶
        if not self.backend.gemini_api_key:
            messagebox.showerror("éŒ¯èª¤", "è«‹å…ˆè¨­ç½®ä¸¦æ¸¬è©¦ API Key")
            return
        
        if not self.backend.xtts_model:
            messagebox.showerror("éŒ¯èª¤", "è«‹å…ˆè¼‰å…¥ XTTS æ¨¡å‹")
            return
        
        if self.enable_voice_var.get() and not self.backend.is_voice_cloned:
            messagebox.showerror("éŒ¯èª¤", "èªéŸ³è¼¸å‡ºå·²å•Ÿç”¨ï¼Œè«‹å…ˆéŒ„è£½èªéŸ³")
            return
        
        # è¨­ç½®èªè¨€
        self.backend.source_language = self.source_lang_var.get()
        self.backend.target_language = self.target_lang_var.get()
        
        # è¨­ç½®èªéŸ³æ–‡ä»¶
        if self.enable_voice_var.get() and self.voice_var.get():
            self.backend.cloned_voice_path = os.path.join("cloned_voices", self.voice_var.get())
        
        # æ¸…ç©ºé€å­—ç¨¿
        self.original_text.delete('1.0', tk.END)
        self.translated_text.delete('1.0', tk.END)
        
        # é–‹å§‹éŒ„éŸ³å’Œç¿»è­¯
        self.is_recording = True
        self.start_btn.config(text="â¹ï¸ åœæ­¢ç¿»è­¯", bg=self.colors['button_bg'])
        self.start_recording_animation()
        self.update_status("ğŸ¤ æ­£åœ¨ç›£è½...")
        
        # å•Ÿå‹•å¾Œç«¯ç¿»è­¯ç³»çµ±
        self.backend.start_real_time_translation_gui(self)
    
    def stop_translation(self):
        """åœæ­¢å³æ™‚ç¿»è­¯"""
        self.is_recording = False
        self.start_btn.config(text="ğŸš€ é–‹å§‹å³æ™‚ç¿»è­¯", bg=self.colors['button_bg'])
        self.stop_recording_animation()
        self.update_status("â¹ï¸ ç¿»è­¯å·²åœæ­¢")
        
        # åœæ­¢å¾Œç«¯ç¿»è­¯ç³»çµ±
        self.backend.stop_real_time_translation()
    
    def start_recording_animation(self):
        """é–‹å§‹éŒ„éŸ³å‹•ç•«æ•ˆæœ"""
        def animate():
            if self.is_recording:
                current_bg = self.start_btn.cget('bg')
                if current_bg == self.colors['button_bg']:
                    self.start_btn.config(bg=self.colors['button_hover'], relief='raised')
                else:
                    self.start_btn.config(bg=self.colors['button_bg'], relief='sunken')
                self.recording_animation_id = self.root.after(500, animate)
        animate()
    
    def stop_recording_animation(self):
        """åœæ­¢éŒ„éŸ³å‹•ç•«æ•ˆæœ"""
        if self.recording_animation_id:
            self.root.after_cancel(self.recording_animation_id)
            self.recording_animation_id = None
        self.start_btn.config(relief='raised')
    
    def update_status(self, message):
        """æ›´æ–°ç‹€æ…‹é¡¯ç¤º"""
        self.status_label.config(text=message)
        self.root.update_idletasks()
    
    def add_original_text(self, text):
        """æ·»åŠ åŸæ–‡åˆ°é€å­—ç¨¿"""
        timestamp = datetime.now().strftime("%H:%M:%S")
        self.original_text.insert(tk.END, f"[{timestamp}] {text}\n")
        self.original_text.see(tk.END)
    
    def add_translated_text(self, text):
        """æ·»åŠ ç¿»è­¯åˆ°é€å­—ç¨¿"""
        timestamp = datetime.now().strftime("%H:%M:%S")
        self.translated_text.insert(tk.END, f"[{timestamp}] {text}\n")
        self.translated_text.see(tk.END)
    
    def run(self):
        """é‹è¡Œ GUI"""
        # è¨­ç½®é—œé–‰äº‹ä»¶
        self.root.protocol("WM_DELETE_WINDOW", self.on_closing)
        self.root.mainloop()
    
    def on_closing(self):
        """é—œé–‰æ‡‰ç”¨ç¨‹åº"""
        if self.is_recording:
            self.stop_translation()
        self.root.destroy()

class RealTimeVoiceTranslationSystem:
    def __init__(self):
        # ç³»çµ±ç‹€æ…‹
        self.gemini_api_key = None
        self.model = None
        self.xtts_model = None
        self.config = None
        
        # èªè¨€è¨­ç½®
        self.source_language = None
        self.target_language = None
        self.supported_languages = {
            'zh': 'ä¸­æ–‡',
            'en': 'è‹±æ–‡', 
            'ja': 'æ—¥æ–‡',
            'ko': 'éŸ“æ–‡',
            'es': 'è¥¿ç­ç‰™æ–‡',
            'fr': 'æ³•æ–‡',
            'de': 'å¾·æ–‡',
            'it': 'æ„å¤§åˆ©æ–‡',
            'pt': 'è‘¡è„ç‰™æ–‡'
        }
        
        # éŸ³é »åƒæ•¸
        self.chunk = 1024
        self.format = pyaudio.paInt16
        self.channels = 1
        self.rate = 16000
        
        # èªéŸ³å…‹éš†
        self.cloned_voice_path = None
        self.is_voice_cloned = False
        
        # å³æ™‚ç¿»è­¯æ§åˆ¶
        self.is_real_time_active = False
        self.should_stop = False
        
        # éŸ³é »è™•ç†éšŠåˆ—
        self.audio_segments_queue = queue.Queue()
        self.translation_queue = queue.Queue()
        self.playback_queue = queue.Queue()
        
        # èªéŸ³æ´»å‹•æª¢æ¸¬
        self.silence_threshold = 500
        self.silence_duration = 1.0  # é™ä½åˆ°1ç§’ä»¥æé«˜éŸ¿æ‡‰é€Ÿåº¦
        self.min_speech_duration = 0.3
        
        # éŸ³é »ç·©è¡
        self.audio_buffer = deque(maxlen=int(self.rate * 10))
        self.current_segment = []
        self.last_speech_time = 0
        self.is_speech_detected = False
        
        # GUI å¼•ç”¨
        self.gui = None
        
        # åˆå§‹åŒ–pygame
        pygame.mixer.init(frequency=24000, size=-16, channels=1, buffer=1024)
        
        print("ğŸ¤ å³æ™‚èªéŸ³å…‹éš†ç¿»è­¯ç³»çµ±å·²å•Ÿå‹•ï¼")
    
    def clone_voice_step_gui(self):
        """GUI ç‰ˆæœ¬çš„èªéŸ³å…‹éš†"""
        try:
            if not os.path.exists("cloned_voices"):
                os.makedirs("cloned_voices")
            
            # éŒ„éŸ³
            audio_frames = []
            audio = pyaudio.PyAudio()
            stream = audio.open(format=self.format,
                              channels=self.channels,
                              rate=self.rate,
                              input=True,
                              frames_per_buffer=self.chunk)
            
            start_time = time.time()
            silence_start = None
            
            while True:
                data = stream.read(self.chunk)
                audio_frames.append(data)
                
                # æª¢æ¸¬éŸ³é‡
                rms = self.calculate_rms(data)
                current_time = time.time()
                
                if rms > self.silence_threshold:
                    silence_start = None
                    if current_time - start_time >= 0.5:  # è‡³å°‘éŒ„éŸ³0.5ç§’
                        pass  # ç¹¼çºŒéŒ„éŸ³
                else:
                    if silence_start is None:
                        silence_start = current_time
                    elif current_time - silence_start >= 2.0 and current_time - start_time >= 1.0:
                        # éœéŸ³2ç§’ä¸”ç¸½éŒ„éŸ³æ™‚é–“è¶…é1ç§’
                        break
                
                # æœ€å¤§éŒ„éŸ³æ™‚é–“é™åˆ¶
                if current_time - start_time >= 10:
                    break
            
            stream.stop_stream()
            stream.close()
            audio.terminate()
            
            # ä¿å­˜èªéŸ³å…‹éš†æ¨£æœ¬
            clone_file = f"cloned_voices/voice_clone_{int(time.time())}.wav"
            
            wf = wave.open(clone_file, 'wb')
            wf.setnchannels(self.channels)
            wf.setsampwidth(pyaudio.PyAudio().get_sample_size(self.format))
            wf.setframerate(self.rate)
            wf.writeframes(b''.join(audio_frames))
            wf.close()
            
            self.cloned_voice_path = clone_file
            self.is_voice_cloned = True
            print(f"âœ… èªéŸ³å…‹éš†å®Œæˆï¼æ¨£æœ¬å·²ä¿å­˜: {clone_file}")
            return True
            
        except Exception as e:
            print(f"âŒ èªéŸ³å…‹éš†å¤±æ•—: {e}")
            return False
    
    def load_xtts_model(self):
        """è¼‰å…¥XTTSæ¨¡å‹"""
        try:
            config = XttsConfig()
            config.load_json("XTTS-v2/config.json")
            self.xtts_model = Xtts.init_from_config(config)
            self.xtts_model.load_checkpoint(config, checkpoint_dir="XTTS-v2/", eval=True)
            
            if torch.cuda.is_available():
                self.xtts_model.cuda()
                print("âœ… ä½¿ç”¨ GPU åŠ é€Ÿ")
            else:
                print("âœ… ä½¿ç”¨ CPU é‹ç®—")
            
            self.config = config
            print("âœ… XTTS æ¨¡å‹è¼‰å…¥æˆåŠŸï¼")
            return True
            
        except Exception as e:
            print(f"âŒ è¼‰å…¥ XTTS æ¨¡å‹å¤±æ•—: {e}")
            return False
    
    def calculate_rms(self, audio_data):
        """è¨ˆç®—éŸ³é »RMSå€¼"""
        if not audio_data or len(audio_data) == 0:
            return 0
        
        try:
            audio_np = np.frombuffer(audio_data, dtype=np.int16)
            if len(audio_np) == 0:
                return 0
            
            # è¨ˆç®—RMSå€¼ï¼Œé¿å…æ•¸å­¸è­¦å‘Š
            mean_square = np.mean(audio_np.astype(np.float64)**2)
            if mean_square < 0:
                return 0
            
            return np.sqrt(mean_square)
        except (ValueError, OverflowError):
            return 0
    
    def detect_voice_activity(self, audio_data):
        """èªéŸ³æ´»å‹•æª¢æ¸¬"""
        rms = self.calculate_rms(audio_data)
        current_time = time.time()
        
        if rms > self.silence_threshold:
            if not self.is_speech_detected:
                self.is_speech_detected = True
                if self.gui:
                    self.gui.root.after(0, lambda: self.gui.update_status("ğŸ¤ æª¢æ¸¬åˆ°èªéŸ³..."))
            self.last_speech_time = current_time
            return True
        else:
            if self.is_speech_detected:
                silence_duration = current_time - self.last_speech_time
                if silence_duration >= self.silence_duration:
                    self.is_speech_detected = False
                    if self.gui:
                        self.gui.root.after(0, lambda: self.gui.update_status("ğŸ”„ è™•ç†èªéŸ³..."))
                    return False
            return self.is_speech_detected
    
    def start_real_time_translation_gui(self, gui):
        """GUI ç‰ˆæœ¬çš„å³æ™‚ç¿»è­¯"""
        self.gui = gui
        
        # é‡ç½®ç‹€æ…‹
        self.is_real_time_active = True
        self.should_stop = False
        
        # å•Ÿå‹•å·¥ä½œç·šç¨‹
        threads = []
        
        # éŸ³é »æ•ç²ç·šç¨‹
        capture_thread = threading.Thread(target=self.audio_capture_worker)
        capture_thread.daemon = True
        capture_thread.start()
        threads.append(capture_thread)
        
        # ç¿»è­¯è™•ç†ç·šç¨‹
        translation_thread = threading.Thread(target=self.translation_worker_gui)
        translation_thread.daemon = True
        translation_thread.start()
        threads.append(translation_thread)
        
        # éŸ³é »æ’­æ”¾ç·šç¨‹ï¼ˆå¦‚æœå•Ÿç”¨ï¼‰
        if gui.enable_voice_var.get():
            playback_thread = threading.Thread(target=self.playback_worker)
            playback_thread.daemon = True
            playback_thread.start()
            threads.append(playback_thread)
        
        self.threads = threads
    
    def stop_real_time_translation(self):
        """åœæ­¢å³æ™‚ç¿»è­¯"""
        self.should_stop = True
        self.is_real_time_active = False
        
        # ç­‰å¾…ç·šç¨‹çµæŸ
        if hasattr(self, 'threads'):
            for thread in self.threads:
                thread.join(timeout=3)
    
    def audio_capture_worker(self):
        """éŸ³é »æ•ç²å·¥ä½œç·šç¨‹"""
        audio = pyaudio.PyAudio()
        stream = audio.open(format=self.format,
                          channels=self.channels,
                          rate=self.rate,
                          input=True,
                          frames_per_buffer=self.chunk)
        
        print("ğŸ¤ é–‹å§‹å³æ™‚èªéŸ³ç›£è½...")
        
        while self.is_real_time_active:
            try:
                data = stream.read(self.chunk, exception_on_overflow=False)
                self.audio_buffer.extend(np.frombuffer(data, dtype=np.int16))
                
                is_speech = self.detect_voice_activity(data)
                
                if is_speech:
                    self.current_segment.extend(np.frombuffer(data, dtype=np.int16))
                elif self.current_segment and len(self.current_segment) > int(self.rate * self.min_speech_duration):
                    # èªéŸ³æ®µçµæŸï¼Œç™¼é€è™•ç†
                    segment_audio = np.array(self.current_segment, dtype=np.int16)
                    self.audio_segments_queue.put(segment_audio)
                    self.current_segment = []
                
                if self.should_stop:
                    break
                    
            except Exception as e:
                print(f"âŒ éŸ³é »æ•ç²éŒ¯èª¤: {e}")
                break
        
        stream.stop_stream()
        stream.close()
        audio.terminate()
        print("ğŸ¤ éŸ³é »æ•ç²å·²åœæ­¢")
    
    def translation_worker_gui(self):
        """GUI ç‰ˆæœ¬çš„ç¿»è­¯è™•ç†å·¥ä½œç·šç¨‹"""
        print("ğŸ”„ ç¿»è­¯è™•ç†ç·šç¨‹å·²å•Ÿå‹•")
        
        while self.is_real_time_active or not self.audio_segments_queue.empty():
            try:
                audio_segment = self.audio_segments_queue.get(timeout=1)
                
                # ä¿å­˜éŸ³é »æ®µåˆ°è‡¨æ™‚æ–‡ä»¶
                temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.wav')
                scipy.io.wavfile.write(temp_file.name, self.rate, audio_segment)
                
                # ç¿»è­¯
                original_text, translated_text = self.transcribe_and_translate_gui(temp_file.name)
                
                if original_text and original_text.strip():
                    # æ›´æ–° GUI é€å­—ç¨¿
                    if self.gui:
                        self.gui.root.after(0, lambda t=original_text: self.gui.add_original_text(t))
                
                if translated_text and translated_text.strip():
                    # æ›´æ–° GUI ç¿»è­¯
                    if self.gui:
                        self.gui.root.after(0, lambda t=translated_text: self.gui.add_translated_text(t))
                    
                    # èªéŸ³åˆæˆï¼ˆå¦‚æœå•Ÿç”¨ï¼‰
                    if self.gui and self.gui.enable_voice_var.get():
                        output_file = self.synthesize_speech(translated_text)
                        if output_file:
                            self.playback_queue.put(output_file)
                
                # æ¸…ç†è‡¨æ™‚æ–‡ä»¶
                os.unlink(temp_file.name)
                self.audio_segments_queue.task_done()
                
            except queue.Empty:
                continue
            except Exception as e:
                print(f"âŒ ç¿»è­¯è™•ç†éŒ¯èª¤: {e}")
        
        print("ğŸ”„ ç¿»è­¯è™•ç†ç·šç¨‹å·²åœæ­¢")
    
    def transcribe_and_translate_gui(self, audio_file_path):
        """GUI ç‰ˆæœ¬çš„èªéŸ³è½‰æ–‡å­—å’Œç¿»è­¯"""
        try:
            audio_file = genai.upload_file(path=audio_file_path)

            source_lang_name = self.supported_languages[self.source_language]
            target_lang_name = self.supported_languages[self.target_language]
            
            if self.source_language == self.target_language:
                prompt = f"è«‹å°‡é€™æ®µéŸ³é »ä¸­çš„{source_lang_name}èªéŸ³å…§å®¹è½‰æ›ç‚ºæ–‡å­—ã€‚åªå›å‚³è½‰éŒ„çš„æ–‡å­—å…§å®¹ï¼Œä¸è¦åŒ…å«å…¶ä»–èªªæ˜ã€‚"
                response = self.model.generate_content([audio_file, prompt])
                original_text = response.text.strip()
                translated_text = original_text
            else:
                transcribe_prompt = f"è«‹å°‡é€™æ®µéŸ³é »ä¸­çš„{source_lang_name}èªéŸ³å…§å®¹è½‰æ›ç‚ºæ–‡å­—ã€‚åªå›å‚³è½‰éŒ„çš„æ–‡å­—å…§å®¹ï¼Œä¸è¦åŒ…å«å…¶ä»–èªªæ˜ã€‚"
                transcribe_response = self.model.generate_content([audio_file, transcribe_prompt])
                original_text = transcribe_response.text.strip()

                translate_prompt = f"è«‹å°‡ä»¥ä¸‹{source_lang_name}æ–‡å­—ç¿»è­¯ç‚º{target_lang_name}ã€‚åªå›å‚³ç¿»è­¯å¾Œçš„æ–‡å­—å…§å®¹ï¼Œä¸è¦åŒ…å«å…¶ä»–èªªæ˜ã€‚\n\n{original_text}"
                translate_response = self.model.generate_content(translate_prompt)
                translated_text = translate_response.text.strip()
            
            genai.delete_file(audio_file.name)
            
            print(f"ğŸ“ åŸæ–‡: {original_text}")
            print(f"ğŸŒ ç¿»è­¯: {translated_text}")
            return original_text, translated_text
            
        except Exception as e:
            print(f"âŒ ç¿»è­¯éŒ¯èª¤: {e}")
            return None, None
    
    def playback_worker(self):
        """éŸ³é »æ’­æ”¾å·¥ä½œç·šç¨‹"""
        print("ğŸ”Š éŸ³é »æ’­æ”¾ç·šç¨‹å·²å•Ÿå‹•")
        
        while self.is_real_time_active or not self.playback_queue.empty():
            try:
                audio_file = self.playback_queue.get(timeout=1)
                
                # æ’­æ”¾éŸ³é »
                pygame.mixer.music.load(audio_file)
                pygame.mixer.music.play()
                
                # ç­‰å¾…æ’­æ”¾å®Œæˆ
                while pygame.mixer.music.get_busy():
                    time.sleep(0.1)
                    if self.should_stop:
                        pygame.mixer.music.stop()
                        break
                
                # æ¸…ç†éŸ³é »æ–‡ä»¶
                try:
                    os.unlink(audio_file)
                except:
                    pass
                
                self.playback_queue.task_done()
                
            except queue.Empty:
                continue
            except Exception as e:
                print(f"âŒ éŸ³é »æ’­æ”¾éŒ¯èª¤: {e}")
        
        print("ğŸ”Š éŸ³é »æ’­æ”¾ç·šç¨‹å·²åœæ­¢")
    
    def synthesize_speech(self, text):
        """ä½¿ç”¨å…‹éš†èªéŸ³åˆæˆèªéŸ³"""
        try:
            if not self.cloned_voice_path or not os.path.exists(self.cloned_voice_path):
                print("âŒ æ²’æœ‰å¯ç”¨çš„å…‹éš†èªéŸ³")
                return None
            
            # æª¢æ¸¬ç›®æ¨™èªè¨€
            language_map = {
                'zh': 'zh-cn',
                'en': 'en',
                'ja': 'ja',
                'ko': 'ko',
                'es': 'es',
                'fr': 'fr',
                'de': 'de',
                'it': 'it',
                'pt': 'pt'
            }
            
            xtts_language = language_map.get(self.target_language, 'en')
            
            # é‡å°æ—¥èªè™•ç†ï¼Œæ·»åŠ ç‰¹æ®Šè™•ç†
            if xtts_language == 'ja':
                print("ğŸ‡¯ğŸ‡µ æ­£åœ¨åˆæˆæ—¥èªèªéŸ³...")
                # æª¢æŸ¥æ˜¯å¦æœ‰å¯ç”¨çš„æ—¥èªè©å…¸
                if not mecab_available:
                    print("âš ï¸ æ—¥èªè©å…¸ä¸å¯ç”¨ï¼Œå°‡ä½¿ç”¨è‹±èªåˆæˆ")
                    xtts_language = 'en'
            
            outputs = self.xtts_model.synthesize(
                text,
                self.config,
                speaker_wav=self.cloned_voice_path,
                gpt_cond_len=3,
                language=xtts_language,
            )
            
            # ä¿å­˜éŸ³é »
            output_file = tempfile.NamedTemporaryFile(delete=False, suffix='.wav')
            scipy.io.wavfile.write(output_file.name, rate=24000, data=outputs["wav"])
            
            language_name = {'zh-cn': 'ä¸­æ–‡', 'en': 'è‹±èª', 'ja': 'æ—¥èª'}.get(xtts_language, xtts_language)
            print(f"ğŸ”Š {language_name}èªéŸ³åˆæˆå®Œæˆ")
            return output_file.name
            
        except Exception as e:
            error_msg = str(e)
            if any(keyword in error_msg for keyword in ["MeCab", "fugashi", "dictionary format", "GenericTagger"]):
                print("âš ï¸ æ—¥èªè™•ç†çµ„ä»¶å•é¡Œï¼Œå˜—è©¦ä½¿ç”¨è‹±èªåˆæˆ...")
                try:
                    # å˜—è©¦ç”¨è‹±èªåˆæˆ
                    outputs = self.xtts_model.synthesize(
                        text,
                        self.config,
                        speaker_wav=self.cloned_voice_path,
                        gpt_cond_len=3,
                        language='en',
                    )
                    output_file = tempfile.NamedTemporaryFile(delete=False, suffix='.wav')
                    scipy.io.wavfile.write(output_file.name, rate=24000, data=outputs["wav"])
                    print("ğŸ”Š ä½¿ç”¨è‹±èªèªéŸ³åˆæˆå®Œæˆ")
                    return output_file.name
                except Exception as fallback_e:
                    print(f"âŒ å‚™ç”¨èªéŸ³åˆæˆä¹Ÿå¤±æ•—: {fallback_e}")
                    return None
            else:
                print(f"âŒ èªéŸ³åˆæˆéŒ¯èª¤: {e}")
                return None
    
    def run(self):
        """é‹è¡Œä¸»ç¨‹åº"""
        print("ğŸ¤ æ­¡è¿ä½¿ç”¨å³æ™‚èªéŸ³å…‹éš†ç¿»è­¯ç³»çµ±ï¼")
        
        # ç³»çµ±è¨­ç½®
        if not self.setup_system():
            print("âŒ ç³»çµ±è¨­ç½®å¤±æ•—ï¼Œç¨‹åºé€€å‡º")
            return
        
        print("\n" + "=" * 60)
        print("ğŸ‰ ç³»çµ±è¨­ç½®å®Œæˆï¼")
        print("=" * 60)
        
        while True:
            print("\nğŸ“‹ æ“ä½œé¸é …:")
            print("  c - å…‹éš†èªéŸ³ï¼ˆå¿…é ˆå…ˆå®Œæˆï¼‰")
            print("  enter - é–‹å§‹å³æ™‚ç¿»è­¯")
            print("  q - é€€å‡ºç¨‹åº")
            
            if self.is_voice_cloned:
                print("âœ… èªéŸ³å·²å…‹éš†ï¼Œå¯ä»¥é–‹å§‹å³æ™‚ç¿»è­¯")
            else:
                print("âš ï¸ è«‹å…ˆæŒ‰ 'c' å®ŒæˆèªéŸ³å…‹éš†")
            
            try:
                choice = input("\nè«‹é¸æ“‡æ“ä½œ: ").strip().lower()
                
                if choice == 'q':
                    print("ğŸ‘‹ å†è¦‹ï¼")
                    break
                elif choice == 'c':
                    if self.clone_voice_step():
                        print("âœ… èªéŸ³å…‹éš†å®Œæˆï¼Œç¾åœ¨å¯ä»¥é–‹å§‹å³æ™‚ç¿»è­¯äº†ï¼")
                    else:
                        print("âŒ èªéŸ³å…‹éš†å¤±æ•—ï¼Œè«‹é‡è©¦")
                elif choice == '' or choice == 'enter':
                    self.start_real_time_translation()
                else:
                    print("âŒ ç„¡æ•ˆé¸é …ï¼Œè«‹é‡æ–°é¸æ“‡")
                    
            except KeyboardInterrupt:
                print("\nğŸ‘‹ ç¨‹åºè¢«ä¸­æ–·ï¼Œå†è¦‹ï¼")
                break
            except Exception as e:
                print(f"âŒ ç™¼ç”ŸéŒ¯èª¤: {e}")

# ä¸»ç¨‹åºå…¥å£
if __name__ == "__main__":
    # æª¢æŸ¥æ˜¯å¦ä½¿ç”¨ GUI æ¨¡å¼
    import sys
    
    if len(sys.argv) > 1 and sys.argv[1] == "--cli":
        # å‘½ä»¤è¡Œæ¨¡å¼
        system = RealTimeVoiceTranslationSystem()
        system.run()
    else:
        # GUI æ¨¡å¼ï¼ˆé»˜èªï¼‰
        app = VoiceTranslationGUI()
        app.run()