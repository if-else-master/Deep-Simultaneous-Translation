import pyaudio
import wave
import threading
import time
import io
import google.generativeai as genai
from TTS.tts.configs.xtts_config import XttsConfig
from TTS.tts.models.xtts import Xtts
import torch
import scipy.io.wavfile
import numpy as np
import pygame
import tempfile
import os
import shutil

class VoiceTranslationSystem:
    def __init__(self, gemini_api_key):
        # åˆå§‹åŒ– Gemini API
        genai.configure(api_key=gemini_api_key)
        self.model = genai.GenerativeModel('gemini-2.0-flash-exp')
        
        # åˆå§‹åŒ– XTTS æ¨¡å‹
        print("æ­£åœ¨è¼‰å…¥ XTTS æ¨¡å‹...")
        config = XttsConfig()
        config.load_json("XTTS-v2/config.json")
        self.xtts_model = Xtts.init_from_config(config)
        self.xtts_model.load_checkpoint(config, checkpoint_dir="XTTS-v2/", eval=True)
        
        if torch.cuda.is_available():
            self.xtts_model.cuda()
            print("ä½¿ç”¨ GPU åŠ é€Ÿ")
        
        self.config = config
        
        # éŸ³é »åƒæ•¸
        self.chunk = 1024
        self.format = pyaudio.paInt16
        self.channels = 1
        self.rate = 44100
        self.record_seconds = 10  # æœ€å¤§éŒ„éŸ³æ™‚é–“
        
        # åˆå§‹åŒ– pygame ç”¨æ–¼æ’­æ”¾éŸ³é »
        pygame.mixer.init()
        
        # éŒ„éŸ³æ§åˆ¶
        self.is_recording = False
        self.audio_frames = []
        
        # èªéŸ³å…‹éš†ç›¸é—œ
        self.cloned_voice_path = None
        
        print("ç³»çµ±åˆå§‹åŒ–å®Œæˆï¼")
    
    def start_recording(self):
        """é–‹å§‹éŒ„éŸ³"""
        self.is_recording = True
        self.audio_frames = []
        
        audio = pyaudio.PyAudio()
        stream = audio.open(format=self.format,
                          channels=self.channels,
                          rate=self.rate,
                          input=True,
                          frames_per_buffer=self.chunk)
        
        print("ğŸ¤ éŒ„éŸ³ä¸­... æŒ‰ Enter åœæ­¢éŒ„éŸ³")
        
        while self.is_recording:
            data = stream.read(self.chunk)
            self.audio_frames.append(data)
        
        print("ğŸ“ éŒ„éŸ³çµæŸ")
        stream.stop_stream()
        stream.close()
        audio.terminate()
    
    def stop_recording(self):
        """åœæ­¢éŒ„éŸ³"""
        self.is_recording = False
    
    def save_audio_to_temp(self, suffix='_original'):
        """å°‡éŒ„éŸ³ä¿å­˜åˆ°è‡¨æ™‚æ–‡ä»¶"""
        if not self.audio_frames:
            return None
        
        # å‰µå»ºè‡¨æ™‚æ–‡ä»¶
        temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=f'{suffix}.wav')
        
        audio = pyaudio.PyAudio()
        wf = wave.open(temp_file.name, 'wb')
        wf.setnchannels(self.channels)
        wf.setsampwidth(audio.get_sample_size(self.format))
        wf.setframerate(self.rate)
        wf.writeframes(b''.join(self.audio_frames))
        wf.close()
        audio.terminate()
        
        return temp_file.name
    
    def clone_voice(self, audio_file_path):
        """å…‹éš†èªéŸ³ - å°‡éŒ„éŸ³æ–‡ä»¶è¤‡è£½ç‚ºèªéŸ³åƒè€ƒ"""
        try:
            print("ğŸ­ æ­£åœ¨å…‹éš†èªéŸ³...")
            
            # å‰µå»ºå…‹éš†èªéŸ³å­˜å„²ç›®éŒ„
            if not os.path.exists("cloned_voices"):
                os.makedirs("cloned_voices")
            
            # å°‡åŸå§‹éŒ„éŸ³è¤‡è£½ä½œç‚ºèªéŸ³å…‹éš†åƒè€ƒ
            cloned_voice_filename = f"cloned_voices/cloned_voice_{int(time.time())}.wav"
            shutil.copy2(audio_file_path, cloned_voice_filename)
            
            self.cloned_voice_path = cloned_voice_filename
            print(f"âœ… èªéŸ³å…‹éš†å®Œæˆï¼Œåƒè€ƒæ–‡ä»¶: {cloned_voice_filename}")
            
            return cloned_voice_filename
            
        except Exception as e:
            print(f"âŒ èªéŸ³å…‹éš†éç¨‹ç™¼ç”ŸéŒ¯èª¤: {e}")
            return None
    
    def transcribe_and_translate(self, audio_file_path, target_language="en"):
        """ä½¿ç”¨ Gemini é€²è¡ŒèªéŸ³è½‰æ–‡å­—å’Œç¿»è­¯"""
        try:
            print("ğŸ¤– æ­£åœ¨ä½¿ç”¨ Gemini é€²è¡ŒèªéŸ³è­˜åˆ¥å’Œç¿»è­¯...")
            
            # ä¸Šå‚³éŸ³é »æ–‡ä»¶
            audio_file = genai.upload_file(path=audio_file_path)
            
            # æ ¹æ“šç›®æ¨™èªè¨€è¨­å®šæç¤ºè©
            if target_language.lower() == "en":
                prompt = "è«‹å°‡é€™æ®µéŸ³é »ä¸­çš„èªéŸ³å…§å®¹è½‰æ›ç‚ºè‹±æ–‡æ–‡å­—ï¼Œå¦‚æœåŸæœ¬å°±æ˜¯è‹±æ–‡å°±ç›´æ¥è½‰éŒ„ï¼Œå¦‚æœæ˜¯å…¶ä»–èªè¨€è«‹ç¿»è­¯æˆè‹±æ–‡ã€‚åªå›å‚³æœ€çµ‚çš„è‹±æ–‡æ–‡å­—å…§å®¹ï¼Œä¸è¦åŒ…å«å…¶ä»–èªªæ˜ã€‚"
            elif target_language.lower() == "zh":
                prompt = "è«‹å°‡é€™æ®µéŸ³é »ä¸­çš„èªéŸ³å…§å®¹è½‰æ›ç‚ºç¹é«”ä¸­æ–‡æ–‡å­—ï¼Œå¦‚æœåŸæœ¬å°±æ˜¯ä¸­æ–‡å°±ç›´æ¥è½‰éŒ„ï¼Œå¦‚æœæ˜¯å…¶ä»–èªè¨€è«‹ç¿»è­¯æˆç¹é«”ä¸­æ–‡ã€‚åªå›å‚³æœ€çµ‚çš„ç¹é«”ä¸­æ–‡æ–‡å­—å…§å®¹ï¼Œä¸è¦åŒ…å«å…¶ä»–èªªæ˜ã€‚"
            else:
                prompt = f"è«‹å°‡é€™æ®µéŸ³é »ä¸­çš„èªéŸ³å…§å®¹è½‰æ›ç‚º{target_language}æ–‡å­—ï¼Œå¦‚æœéœ€è¦ç¿»è­¯è«‹ç¿»è­¯æˆ{target_language}ã€‚åªå›å‚³æœ€çµ‚çš„æ–‡å­—å…§å®¹ï¼Œä¸è¦åŒ…å«å…¶ä»–èªªæ˜ã€‚"
            
            # ç™¼é€è«‹æ±‚åˆ° Gemini
            response = self.model.generate_content([audio_file, prompt])
            
            # æ¸…ç†ä¸Šå‚³çš„æ–‡ä»¶
            genai.delete_file(audio_file.name)
            
            translated_text = response.text.strip()
            print(f"ğŸ“ ç¿»è­¯çµæœ: {translated_text}")
            
            return translated_text
            
        except Exception as e:
            print(f"âŒ ç¿»è­¯éç¨‹ç™¼ç”ŸéŒ¯èª¤: {e}")
            return None
    
    def synthesize_speech_with_cloned_voice(self, text, output_file="output_speech.wav"):
        """ä½¿ç”¨å…‹éš†çš„èªéŸ³åˆæˆèªéŸ³"""
        try:
            print("ğŸ”Š æ­£åœ¨ä½¿ç”¨å…‹éš†èªéŸ³åˆæˆèªéŸ³...")
            
            if not self.cloned_voice_path or not os.path.exists(self.cloned_voice_path):
                print("âŒ æ²’æœ‰å¯ç”¨çš„å…‹éš†èªéŸ³ï¼Œè«‹å…ˆéŒ„éŸ³é€²è¡ŒèªéŸ³å…‹éš†")
                return None
            
            # æª¢æ¸¬èªè¨€
            # ç°¡å–®çš„èªè¨€æª¢æ¸¬ï¼šå¦‚æœåŒ…å«ä¸­æ–‡å­—ç¬¦å°±ç”¨ä¸­æ–‡ï¼Œå¦å‰‡ç”¨è‹±æ–‡
            has_chinese = any('\u4e00' <= char <= '\u9fff' for char in text)
            language = "zh-cn" if has_chinese else "en"
            
            print(f"ğŸŒ æª¢æ¸¬åˆ°èªè¨€: {'ä¸­æ–‡' if language == 'zh-cn' else 'è‹±æ–‡'}")
            
            outputs = self.xtts_model.synthesize(
                text,
                self.config,
                speaker_wav=self.cloned_voice_path,  # ä½¿ç”¨å…‹éš†çš„èªéŸ³
                gpt_cond_len=3,
                language=language,
            )
            
            # ä¿å­˜éŸ³é »
            scipy.io.wavfile.write(output_file, rate=24000, data=outputs["wav"])
            print(f"âœ… èªéŸ³åˆæˆå®Œæˆï¼Œå·²ä¿å­˜åˆ° {output_file}")
            
            return output_file
            
        except AttributeError as e:
            if "'GPT2InferenceModel' object has no attribute 'generate'" in str(e):
                print("âŒ éŒ¯èª¤ï¼štransformersåº«ç‰ˆæœ¬éé«˜ï¼Œè«‹é™ç´šåˆ°4.49.0ç‰ˆæœ¬")
                print("è«‹é‹è¡Œ: pip install transformers==4.49.0")
                return None
            else:
                raise e
        except Exception as e:
            print(f"âŒ èªéŸ³åˆæˆç™¼ç”ŸéŒ¯èª¤: {e}")
            return None
    
    def play_audio(self, audio_file):
        """æ’­æ”¾éŸ³é »æ–‡ä»¶"""
        try:
            print("ğŸ”Š æ­£åœ¨æ’­æ”¾éŸ³é »...")
            pygame.mixer.music.load(audio_file)
            pygame.mixer.music.play()
            
            # ç­‰å¾…æ’­æ”¾å®Œæˆ
            while pygame.mixer.music.get_busy():
                time.sleep(0.1)
                
            print("âœ… æ’­æ”¾å®Œæˆ")
            
        except Exception as e:
            print(f"âŒ æ’­æ”¾éŸ³é »æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
    
    def process_voice_translation(self, target_language="en"):
        """å®Œæ•´çš„èªéŸ³ç¿»è­¯æµç¨‹ï¼šéŒ„éŸ³ â†’ å…‹éš†èªéŸ³ â†’ ç¿»è­¯ â†’ åˆæˆ"""
        # é–‹å§‹éŒ„éŸ³
        recording_thread = threading.Thread(target=self.start_recording)
        recording_thread.start()
        
        # ç­‰å¾…ç”¨æˆ¶æŒ‰ Enter åœæ­¢éŒ„éŸ³
        input()
        self.stop_recording()
        recording_thread.join()
        
        # ä¿å­˜éŒ„éŸ³åˆ°è‡¨æ™‚æ–‡ä»¶
        temp_audio_file = self.save_audio_to_temp()
        
        if not temp_audio_file:
            print("âŒ æ²’æœ‰éŒ„éŸ³æ•¸æ“š")
            return False
        
        try:
            # æ­¥é©Ÿ1: å…‹éš†èªéŸ³
            print("\n=== æ­¥é©Ÿ 1: èªéŸ³å…‹éš† ===")
            cloned_voice_file = self.clone_voice(temp_audio_file)
            
            if not cloned_voice_file:
                return False
            
            # æ­¥é©Ÿ2: ç¿»è­¯éŸ³é »å…§å®¹
            print("\n=== æ­¥é©Ÿ 2: èªéŸ³ç¿»è­¯ ===")
            translated_text = self.transcribe_and_translate(temp_audio_file, target_language)
            
            if not translated_text:
                return False
            
            # æ­¥é©Ÿ3: ä½¿ç”¨å…‹éš†èªéŸ³åˆæˆç¿»è­¯å¾Œçš„å…§å®¹
            print("\n=== æ­¥é©Ÿ 3: èªéŸ³åˆæˆ ===")
            output_file = self.synthesize_speech_with_cloned_voice(translated_text)
            
            if not output_file:
                return False
            
            # æ­¥é©Ÿ4: æ’­æ”¾çµæœ
            print("\n=== æ­¥é©Ÿ 4: æ’­æ”¾çµæœ ===")
            self.play_audio(output_file)
            
            return True
            
        finally:
            # æ¸…ç†è‡¨æ™‚æ–‡ä»¶
            try:
                if temp_audio_file and os.path.exists(temp_audio_file):
                    os.unlink(temp_audio_file)
            except:
                pass
    
    def show_cloned_voices(self):
        """é¡¯ç¤ºå·²å…‹éš†çš„èªéŸ³æ–‡ä»¶"""
        if not os.path.exists("cloned_voices"):
            print("ğŸ“ é‚„æ²’æœ‰å…‹éš†çš„èªéŸ³æ–‡ä»¶")
            return
        
        voices = [f for f in os.listdir("cloned_voices") if f.endswith('.wav')]
        if not voices:
            print("ğŸ“ é‚„æ²’æœ‰å…‹éš†çš„èªéŸ³æ–‡ä»¶")
            return
        
        print("ğŸ“ å·²å…‹éš†çš„èªéŸ³æ–‡ä»¶:")
        for i, voice in enumerate(voices, 1):
            print(f"  {i}. {voice}")
    
    def clean_cloned_voices(self):
        """æ¸…ç†æ‰€æœ‰å…‹éš†çš„èªéŸ³æ–‡ä»¶"""
        if os.path.exists("cloned_voices"):
            try:
                shutil.rmtree("cloned_voices")
                print("ğŸ—‘ï¸ å·²æ¸…ç†æ‰€æœ‰å…‹éš†çš„èªéŸ³æ–‡ä»¶")
                self.cloned_voice_path = None
            except Exception as e:
                print(f"âŒ æ¸…ç†å¤±æ•—: {e}")
        else:
            print("ğŸ“ æ²’æœ‰éœ€è¦æ¸…ç†çš„æ–‡ä»¶")
    
    def run_translation_loop(self, target_language="en"):
        """é‹è¡Œç¿»è­¯å¾ªç’°"""
        print("ğŸš€ èªéŸ³å…‹éš†ç¿»è­¯ç³»çµ±å•Ÿå‹•ï¼")
        print("\n=== ç³»çµ±æµç¨‹ ===")
        print("1. ğŸ¤ éŒ„éŸ³ - éŒ„è£½ä½ çš„èªéŸ³")
        print("2. ğŸ­ å…‹éš† - å…‹éš†ä½ çš„éŸ³è‰²")
        print("3. ğŸ¤– ç¿»è­¯ - ç¿»è­¯èªéŸ³å…§å®¹")
        print("4. ğŸ”Š åˆæˆ - ç”¨ä½ çš„éŸ³è‰²èªªå‡ºç¿»è­¯çµæœ")
        
        print("\n=== æŒ‡ä»¤èªªæ˜ ===")
        print("- è¼¸å…¥ 'start' æˆ– 's' é–‹å§‹å®Œæ•´æµç¨‹")
        print("- è¼¸å…¥ 'lang en' è¨­å®šç¿»è­¯ç‚ºè‹±æ–‡")
        print("- è¼¸å…¥ 'lang zh' è¨­å®šç¿»è­¯ç‚ºä¸­æ–‡")
        print("- è¼¸å…¥ 'voices' æŸ¥çœ‹å·²å…‹éš†çš„èªéŸ³")
        print("- è¼¸å…¥ 'clean' æ¸…ç†æ‰€æœ‰å…‹éš†èªéŸ³")
        print("- è¼¸å…¥ 'quit' æˆ– 'q' é€€å‡ºç¨‹å¼")
        
        print(f"\nç›®å‰ç¿»è­¯èªè¨€: {'è‹±æ–‡' if target_language == 'en' else 'ä¸­æ–‡'}")
        
        while True:
            try:
                command = input("\nè«‹è¼¸å…¥æŒ‡ä»¤: ").strip().lower()
                
                if command in ['quit', 'q']:
                    print("ğŸ‘‹ å†è¦‹ï¼")
                    break
                
                elif command.startswith('lang '):
                    new_lang = command.split(' ')[1]
                    if new_lang in ['en', 'zh']:
                        target_language = new_lang
                        print(f"âœ… ç¿»è­¯èªè¨€å·²è¨­å®šç‚º: {'è‹±æ–‡' if target_language == 'en' else 'ä¸­æ–‡'}")
                    else:
                        print("âŒ æ”¯æ´çš„èªè¨€: en (è‹±æ–‡), zh (ä¸­æ–‡)")
                
                elif command == 'voices':
                    self.show_cloned_voices()
                
                elif command == 'clean':
                    self.clean_cloned_voices()
                
                elif command in ['start', 's']:
                    print("\nğŸ¬ é–‹å§‹èªéŸ³å…‹éš†ç¿»è­¯æµç¨‹...")
                    print("ğŸ“ æº–å‚™éŒ„éŸ³ï¼ŒéŒ„éŸ³æœŸé–“è«‹æ¸…æ¥šèªªè©±ï¼ŒéŒ„éŸ³å°‡ç”¨æ–¼èªéŸ³å…‹éš†å’Œç¿»è­¯")
                    
                    success = self.process_voice_translation(target_language)
                    
                    if success:
                        print("\nğŸ‰ èªéŸ³å…‹éš†ç¿»è­¯æµç¨‹å®Œæˆï¼")
                    else:
                        print("\nâŒ æµç¨‹åŸ·è¡Œå¤±æ•—ï¼Œè«‹é‡è©¦")
                
                else:
                    print("âŒ æœªçŸ¥æŒ‡ä»¤ï¼Œè«‹è¼¸å…¥ 'start' é–‹å§‹æµç¨‹æˆ– 'quit' é€€å‡º")
                    
            except KeyboardInterrupt:
                print("\nğŸ‘‹ ç¨‹å¼è¢«ä¸­æ–·ï¼Œå†è¦‹ï¼")
                break
            except Exception as e:
                print(f"âŒ ç™¼ç”ŸéŒ¯èª¤: {e}")

# ä½¿ç”¨ç¯„ä¾‹
if __name__ == "__main__":
    # è«‹æ›¿æ›ç‚ºä½ çš„ Gemini API Key
    GEMINI_API_KEY = "XXXX"
    
    # åˆå§‹åŒ–ç³»çµ±ï¼ˆä¸éœ€è¦é è¨­çš„åƒè€ƒèªéŸ³ï¼Œå› ç‚ºæœƒç”¨å…‹éš†çš„èªéŸ³ï¼‰
    system = VoiceTranslationSystem(gemini_api_key=GEMINI_API_KEY)
    
    # é‹è¡Œç¿»è­¯å¾ªç’°ï¼Œé è¨­ç¿»è­¯ç‚ºè‹±æ–‡
    system.run_translation_loop(target_language="en")