import pyaudio
import wave
import threading
import time
import io
import google.generativeai as genai
from TTS.tts.configs.xtts_config import XttsConfig
from TTS.tts.models.xtts import Xtts
import torch
import scipy.io.wavfile
import numpy as np
import pygame
import tempfile
import os
import shutil
import queue
from collections import deque
import getpass

def setup_mecab():
    """è¨­ç½® MeCab é…ç½®ä»¥æ”¯æŒæ—¥èªè™•ç†"""
    try:
        import unidic_lite
        dicdir = unidic_lite.dicdir
        mecabrc_path = os.path.join(dicdir, 'mecabrc')
        if os.path.exists(mecabrc_path):
            os.environ['MECABRC'] = mecabrc_path
            print("âœ… ä½¿ç”¨ unidic-lite è©å…¸")
            return True
        else:
            print("âœ… unidic-lite å¯ç”¨ï¼Œä½¿ç”¨é è¨­é…ç½®")
            return True
    except (ImportError, AttributeError):
        pass
    possible_paths = [
        '/opt/homebrew/etc/mecabrc',  # Homebrew Apple Silicon
        '/usr/local/etc/mecabrc',     # Homebrew Intel
        '/usr/etc/mecabrc',           # ç³»çµ±å®‰è£
    ]
    
    for path in possible_paths:
        if os.path.exists(path):
            os.environ['MECABRC'] = path
            print(f"âœ… ä½¿ç”¨ç³»çµ± MeCab é…ç½®: {path}")
            return True
    
    print("âš ï¸ æœªæ‰¾åˆ° MeCab é…ç½®ï¼Œæ—¥èªè™•ç†å¯èƒ½å—é™")
    return False

# åˆå§‹åŒ– MeCab é…ç½®
mecab_available = setup_mecab()

class RealTimeVoiceTranslationSystem:
    def __init__(self):
        # ç³»çµ±ç‹€æ…‹
        self.gemini_api_key = None
        self.model = None
        self.xtts_model = None
        self.config = None
        
        # èªè¨€è¨­ç½®
        self.source_language = None
        self.target_language = None
        self.supported_languages = {
            'zh': 'ä¸­æ–‡',
            'en': 'è‹±æ–‡', 
            'ja': 'æ—¥æ–‡',
            'ko': 'éŸ“æ–‡',
            'es': 'è¥¿ç­ç‰™æ–‡',
            'fr': 'æ³•æ–‡',
            'de': 'å¾·æ–‡',
            'it': 'æ„å¤§åˆ©æ–‡',
            'pt': 'è‘¡è„ç‰™æ–‡'
        }
        
        # éŸ³é »åƒæ•¸
        self.chunk = 1024
        self.format = pyaudio.paInt16
        self.channels = 1
        self.rate = 16000
        
        # èªéŸ³å…‹éš†
        self.cloned_voice_path = None
        self.is_voice_cloned = False
        
        # å³æ™‚ç¿»è­¯æ§åˆ¶
        self.is_real_time_active = False
        self.should_stop = False
        
        # éŸ³é »è™•ç†éšŠåˆ—
        self.audio_segments_queue = queue.Queue()
        self.translation_queue = queue.Queue()
        self.playback_queue = queue.Queue()
        
        # èªéŸ³æ´»å‹•æª¢æ¸¬
        self.silence_threshold = 500
        self.silence_duration = 1.0  # é™ä½åˆ°1ç§’ä»¥æé«˜éŸ¿æ‡‰é€Ÿåº¦
        self.min_speech_duration = 0.3
        
        # éŸ³é »ç·©è¡
        self.audio_buffer = deque(maxlen=int(self.rate * 10))
        self.current_segment = []
        self.last_speech_time = 0
        self.is_speech_detected = False
        
        # åˆå§‹åŒ–pygame
        pygame.mixer.init(frequency=24000, size=-16, channels=1, buffer=1024)
        
        print("ğŸ¤ å³æ™‚èªéŸ³å…‹éš†ç¿»è­¯ç³»çµ±å·²å•Ÿå‹•ï¼")
    
    def setup_system(self):
        """ç³»çµ±åˆå§‹åŒ–è¨­ç½®"""
        print("=" * 60)
        print("ğŸš€ å³æ™‚èªéŸ³å…‹éš†ç¿»è­¯ç³»çµ±è¨­ç½®")
        print("=" * 60)
        
        # 1. è¼¸å…¥API Key
        if not self.setup_gemini_api():
            return False
        
        # 2. é¸æ“‡èªè¨€
        if not self.setup_languages():
            return False
        
        # 3. è¼‰å…¥XTTSæ¨¡å‹
        if not self.load_xtts_model():
            return False
        
        return True
    
    def setup_gemini_api(self):
        """è¨­ç½®Gemini API"""
        print("\nğŸ“¡ è¨­ç½® Gemini API")
        print("-" * 30)
        
        while True:
            try:
                api_key = getpass.getpass("è«‹è¼¸å…¥æ‚¨çš„ Gemini API Key: ").strip()
                
                if not api_key:
                    print("âŒ API Key ä¸èƒ½ç‚ºç©ºï¼Œè«‹é‡æ–°è¼¸å…¥")
                    continue
                
                # æ¸¬è©¦API Key
                genai.configure(api_key=api_key)
                test_model = genai.GenerativeModel('gemini-2.0-flash-exp')
                test_response = test_model.generate_content("æ¸¬è©¦")
                
                self.gemini_api_key = api_key
                self.model = test_model
                print("âœ… Gemini API è¨­ç½®æˆåŠŸï¼")
                return True
                
            except Exception as e:
                print(f"âŒ API Key ç„¡æ•ˆ: {e}")
                retry = input("æ˜¯å¦é‡æ–°è¼¸å…¥ï¼Ÿ(y/n): ").strip().lower()
                if retry != 'y':
                    return False
    
    def setup_languages(self):
        """è¨­ç½®èªè¨€é¸é …"""
        print("\nğŸŒ èªè¨€è¨­ç½®")
        print("-" * 30)
        
        # é¡¯ç¤ºæ”¯æŒçš„èªè¨€
        print("æ”¯æŒçš„èªè¨€:")
        for code, name in self.supported_languages.items():
            print(f"  {code}: {name}")
        
        # é¸æ“‡åŸå§‹èªè¨€
        while True:
            source = input("\nè«‹é¸æ“‡æ‚¨çš„åŸå§‹èªè¨€ä»£ç¢¼ (ä¾‹: zh): ").strip().lower()
            if source in self.supported_languages:
                self.source_language = source
                print(f"âœ… åŸå§‹èªè¨€: {self.supported_languages[source]}")
                break
            else:
                print("âŒ ä¸æ”¯æŒçš„èªè¨€ä»£ç¢¼ï¼Œè«‹é‡æ–°é¸æ“‡")
        
        # é¸æ“‡ç›®æ¨™èªè¨€
        while True:
            target = input("è«‹é¸æ“‡ç›®æ¨™èªè¨€ä»£ç¢¼ (ä¾‹: ja): ").strip().lower()
            if target in self.supported_languages:
                if target == self.source_language:
                    print("âš ï¸ ç›®æ¨™èªè¨€èˆ‡åŸå§‹èªè¨€ç›¸åŒï¼Œå°‡ç›´æ¥è½‰éŒ„èªéŸ³")
                self.target_language = target
                print(f"âœ… ç›®æ¨™èªè¨€: {self.supported_languages[target]}")
                break
            else:
                print("âŒ ä¸æ”¯æŒçš„èªè¨€ä»£ç¢¼ï¼Œè«‹é‡æ–°é¸æ“‡")
        
        return True
    
    def load_xtts_model(self):
        """è¼‰å…¥XTTSæ¨¡å‹"""
        print("\nğŸ¤– è¼‰å…¥ XTTS èªéŸ³åˆæˆæ¨¡å‹...")
        print("-" * 30)
        
        try:
            config = XttsConfig()
            config.load_json("XTTS-v2/config.json")
            self.xtts_model = Xtts.init_from_config(config)
            self.xtts_model.load_checkpoint(config, checkpoint_dir="XTTS-v2/", eval=True)
            
            if torch.cuda.is_available():
                self.xtts_model.cuda()
                print("âœ… ä½¿ç”¨ GPU åŠ é€Ÿ")
            else:
                print("âœ… ä½¿ç”¨ CPU é‹ç®—")
            
            self.config = config
            print("âœ… XTTS æ¨¡å‹è¼‰å…¥æˆåŠŸï¼")
            return True
            
        except Exception as e:
            print(f"âŒ è¼‰å…¥ XTTS æ¨¡å‹å¤±æ•—: {e}")
            return False
    
    def clone_voice_step(self):
        """èªéŸ³å…‹éš†æ­¥é©Ÿ"""
        print("\nğŸ­ èªéŸ³å…‹éš†æ­¥é©Ÿ")
        print("-" * 30)
        print("ğŸ“‹ èªªæ˜ï¼šç³»çµ±å°‡éŒ„è£½æ‚¨çš„è²éŸ³æ¨£æœ¬ç”¨æ–¼èªéŸ³å…‹éš†")
        print("ğŸ’¡ è«‹ç”¨æ‚¨çš„è‡ªç„¶èªèª¿èªªä¸€æ®µè©±ï¼ˆå»ºè­°3-5ç§’ï¼‰")
        
        input("æº–å‚™å¥½å¾ŒæŒ‰ Enter é–‹å§‹éŒ„éŸ³...")
        
        # éŒ„éŸ³
        print("ğŸ¤ æ­£åœ¨éŒ„éŸ³... è«‹é–‹å§‹èªªè©±")
        audio_frames = []
        
        audio = pyaudio.PyAudio()
        stream = audio.open(format=self.format,
                          channels=self.channels,
                          rate=self.rate,
                          input=True,
                          frames_per_buffer=self.chunk)
        
        start_time = time.time()
        silence_start = None
        
        while True:
            data = stream.read(self.chunk)
            audio_frames.append(data)
            
            # æª¢æ¸¬éŸ³é‡
            rms = self.calculate_rms(data)
            current_time = time.time()
            
            if rms > self.silence_threshold:
                silence_start = None
                if current_time - start_time >= 0.5:  # è‡³å°‘éŒ„éŸ³0.5ç§’
                    print("ğŸ”Š æª¢æ¸¬åˆ°èªéŸ³...")
            else:
                if silence_start is None:
                    silence_start = current_time
                elif current_time - silence_start >= 2.0 and current_time - start_time >= 1.0:
                    # éœéŸ³2ç§’ä¸”ç¸½éŒ„éŸ³æ™‚é–“è¶…é1ç§’
                    break
            
            # æœ€å¤§éŒ„éŸ³æ™‚é–“é™åˆ¶
            if current_time - start_time >= 10:
                break
        
        stream.stop_stream()
        stream.close()
        audio.terminate()
        
        print("ğŸ“ éŒ„éŸ³å®Œæˆï¼Œæ­£åœ¨è™•ç†...")
        
        # ä¿å­˜èªéŸ³å…‹éš†æ¨£æœ¬
        try:
            if not os.path.exists("cloned_voices"):
                os.makedirs("cloned_voices")
            
            clone_file = f"cloned_voices/voice_clone_{int(time.time())}.wav"
            
            wf = wave.open(clone_file, 'wb')
            wf.setnchannels(self.channels)
            wf.setsampwidth(pyaudio.PyAudio().get_sample_size(self.format))
            wf.setframerate(self.rate)
            wf.writeframes(b''.join(audio_frames))
            wf.close()
            
            self.cloned_voice_path = clone_file
            self.is_voice_cloned = True
            print(f"âœ… èªéŸ³å…‹éš†å®Œæˆï¼æ¨£æœ¬å·²ä¿å­˜: {clone_file}")
            return True
            
        except Exception as e:
            print(f"âŒ èªéŸ³å…‹éš†å¤±æ•—: {e}")
            return False
    
    def calculate_rms(self, audio_data):
        """è¨ˆç®—éŸ³é »RMSå€¼"""
        if not audio_data or len(audio_data) == 0:
            return 0
        
        try:
            audio_np = np.frombuffer(audio_data, dtype=np.int16)
            if len(audio_np) == 0:
                return 0
            
            # è¨ˆç®—RMSå€¼ï¼Œé¿å…æ•¸å­¸è­¦å‘Š
            mean_square = np.mean(audio_np.astype(np.float64)**2)
            if mean_square < 0:
                return 0
            
            return np.sqrt(mean_square)
        except (ValueError, OverflowError):
            return 0
    
    def detect_voice_activity(self, audio_data):
        """èªéŸ³æ´»å‹•æª¢æ¸¬"""
        rms = self.calculate_rms(audio_data)
        current_time = time.time()
        
        if rms > self.silence_threshold:
            if not self.is_speech_detected:
                self.is_speech_detected = True
                print("ğŸ¤ é–‹å§‹èªªè©±...")
            self.last_speech_time = current_time
            return True
        else:
            if self.is_speech_detected:
                silence_duration = current_time - self.last_speech_time
                if silence_duration >= self.silence_duration:
                    self.is_speech_detected = False
                    print("â¸ï¸ æª¢æ¸¬åˆ°åœé “ï¼Œè™•ç†èªéŸ³...")
                    return False
            return self.is_speech_detected
    
    def audio_capture_worker(self):
        """éŸ³é »æ•ç²å·¥ä½œç·šç¨‹"""
        audio = pyaudio.PyAudio()
        stream = audio.open(format=self.format,
                          channels=self.channels,
                          rate=self.rate,
                          input=True,
                          frames_per_buffer=self.chunk)
        
        print("ğŸ¤ é–‹å§‹å³æ™‚èªéŸ³ç›£è½...")
        
        while self.is_real_time_active:
            try:
                data = stream.read(self.chunk, exception_on_overflow=False)
                self.audio_buffer.extend(np.frombuffer(data, dtype=np.int16))
                
                is_speech = self.detect_voice_activity(data)
                
                if is_speech:
                    self.current_segment.extend(np.frombuffer(data, dtype=np.int16))
                elif self.current_segment and len(self.current_segment) > int(self.rate * self.min_speech_duration):
                    # èªéŸ³æ®µçµæŸï¼Œç™¼é€è™•ç†
                    segment_audio = np.array(self.current_segment, dtype=np.int16)
                    self.audio_segments_queue.put(segment_audio)
                    self.current_segment = []
                
                if self.should_stop:
                    break
                    
            except Exception as e:
                print(f"âŒ éŸ³é »æ•ç²éŒ¯èª¤: {e}")
                break
        
        stream.stop_stream()
        stream.close()
        audio.terminate()
        print("ğŸ¤ éŸ³é »æ•ç²å·²åœæ­¢")
    
    def translation_worker(self):
        """ç¿»è­¯è™•ç†å·¥ä½œç·šç¨‹"""
        print("ğŸ”„ ç¿»è­¯è™•ç†ç·šç¨‹å·²å•Ÿå‹•")
        
        while self.is_real_time_active or not self.audio_segments_queue.empty():
            try:
                audio_segment = self.audio_segments_queue.get(timeout=1)
                
                # ä¿å­˜éŸ³é »æ®µåˆ°è‡¨æ™‚æ–‡ä»¶
                temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.wav')
                scipy.io.wavfile.write(temp_file.name, self.rate, audio_segment)
                
                # ç¿»è­¯
                translated_text = self.transcribe_and_translate(temp_file.name)
                
                if translated_text and translated_text.strip():
                    # èªéŸ³åˆæˆ
                    output_file = self.synthesize_speech(translated_text)
                    if output_file:
                        self.playback_queue.put(output_file)
                
                # æ¸…ç†è‡¨æ™‚æ–‡ä»¶
                os.unlink(temp_file.name)
                self.audio_segments_queue.task_done()
                
            except queue.Empty:
                continue
            except Exception as e:
                print(f"âŒ ç¿»è­¯è™•ç†éŒ¯èª¤: {e}")
        
        print("ğŸ”„ ç¿»è­¯è™•ç†ç·šç¨‹å·²åœæ­¢")
    
    def playback_worker(self):
        """éŸ³é »æ’­æ”¾å·¥ä½œç·šç¨‹"""
        print("ğŸ”Š éŸ³é »æ’­æ”¾ç·šç¨‹å·²å•Ÿå‹•")
        
        while self.is_real_time_active or not self.playback_queue.empty():
            try:
                audio_file = self.playback_queue.get(timeout=1)
                
                # æ’­æ”¾éŸ³é »
                pygame.mixer.music.load(audio_file)
                pygame.mixer.music.play()
                
                # ç­‰å¾…æ’­æ”¾å®Œæˆ
                while pygame.mixer.music.get_busy():
                    time.sleep(0.1)
                    if self.should_stop:
                        pygame.mixer.music.stop()
                        break
                
                # æ¸…ç†éŸ³é »æ–‡ä»¶
                try:
                    os.unlink(audio_file)
                except:
                    pass
                
                self.playback_queue.task_done()
                
            except queue.Empty:
                continue
            except Exception as e:
                print(f"âŒ éŸ³é »æ’­æ”¾éŒ¯èª¤: {e}")
        
        print("ğŸ”Š éŸ³é »æ’­æ”¾ç·šç¨‹å·²åœæ­¢")
    
    def transcribe_and_translate(self, audio_file_path):
        """èªéŸ³è½‰æ–‡å­—å’Œç¿»è­¯"""
        try:
            audio_file = genai.upload_file(path=audio_file_path)
            
            # æ§‹å»ºç¿»è­¯æç¤ºè©
            source_lang_name = self.supported_languages[self.source_language]
            target_lang_name = self.supported_languages[self.target_language]
            
            if self.source_language == self.target_language:
                prompt = f"è«‹å°‡é€™æ®µéŸ³é »ä¸­çš„{source_lang_name}èªéŸ³å…§å®¹è½‰æ›ç‚ºæ–‡å­—ã€‚åªå›å‚³è½‰éŒ„çš„æ–‡å­—å…§å®¹ï¼Œä¸è¦åŒ…å«å…¶ä»–èªªæ˜ã€‚"
            else:
                prompt = f"è«‹å°‡é€™æ®µéŸ³é »ä¸­çš„{source_lang_name}èªéŸ³å…§å®¹ç¿»è­¯ç‚º{target_lang_name}ã€‚åªå›å‚³ç¿»è­¯å¾Œçš„æ–‡å­—å…§å®¹ï¼Œä¸è¦åŒ…å«å…¶ä»–èªªæ˜ã€‚"
            
            response = self.model.generate_content([audio_file, prompt])
            genai.delete_file(audio_file.name)
            
            result = response.text.strip()
            print(f"ğŸ“ ç¿»è­¯: {result}")
            return result
            
        except Exception as e:
            print(f"âŒ ç¿»è­¯éŒ¯èª¤: {e}")
            return None
    
    def synthesize_speech(self, text):
        """ä½¿ç”¨å…‹éš†èªéŸ³åˆæˆèªéŸ³"""
        try:
            if not self.cloned_voice_path or not os.path.exists(self.cloned_voice_path):
                print("âŒ æ²’æœ‰å¯ç”¨çš„å…‹éš†èªéŸ³")
                return None
            
            # æª¢æ¸¬ç›®æ¨™èªè¨€
            language_map = {
                'zh': 'zh-cn',
                'en': 'en',
                'ja': 'ja',
                'ko': 'ko',
                'es': 'es',
                'fr': 'fr',
                'de': 'de',
                'it': 'it',
                'pt': 'pt'
            }
            
            xtts_language = language_map.get(self.target_language, 'en')
            
            # é‡å°æ—¥èªè™•ç†ï¼Œæ·»åŠ ç‰¹æ®Šè™•ç†
            if xtts_language == 'ja':
                print("ğŸ‡¯ğŸ‡µ æ­£åœ¨åˆæˆæ—¥èªèªéŸ³...")
                # æª¢æŸ¥æ˜¯å¦æœ‰å¯ç”¨çš„æ—¥èªè©å…¸
                if not mecab_available:
                    print("âš ï¸ æ—¥èªè©å…¸ä¸å¯ç”¨ï¼Œå°‡ä½¿ç”¨è‹±èªåˆæˆ")
                    xtts_language = 'en'
            
            outputs = self.xtts_model.synthesize(
                text,
                self.config,
                speaker_wav=self.cloned_voice_path,
                gpt_cond_len=3,
                language=xtts_language,
            )
            
            # ä¿å­˜éŸ³é »
            output_file = tempfile.NamedTemporaryFile(delete=False, suffix='.wav')
            scipy.io.wavfile.write(output_file.name, rate=24000, data=outputs["wav"])
            
            language_name = {'zh-cn': 'ä¸­æ–‡', 'en': 'è‹±èª', 'ja': 'æ—¥èª'}.get(xtts_language, xtts_language)
            print(f"ğŸ”Š {language_name}èªéŸ³åˆæˆå®Œæˆ")
            return output_file.name
            
        except Exception as e:
            error_msg = str(e)
            if any(keyword in error_msg for keyword in ["MeCab", "fugashi", "dictionary format", "GenericTagger"]):
                print("âš ï¸ æ—¥èªè™•ç†çµ„ä»¶å•é¡Œï¼Œå˜—è©¦ä½¿ç”¨è‹±èªåˆæˆ...")
                try:
                    # å˜—è©¦ç”¨è‹±èªåˆæˆ
                    outputs = self.xtts_model.synthesize(
                        text,
                        self.config,
                        speaker_wav=self.cloned_voice_path,
                        gpt_cond_len=3,
                        language='en',
                    )
                    output_file = tempfile.NamedTemporaryFile(delete=False, suffix='.wav')
                    scipy.io.wavfile.write(output_file.name, rate=24000, data=outputs["wav"])
                    print("ğŸ”Š ä½¿ç”¨è‹±èªèªéŸ³åˆæˆå®Œæˆ")
                    return output_file.name
                except Exception as fallback_e:
                    print(f"âŒ å‚™ç”¨èªéŸ³åˆæˆä¹Ÿå¤±æ•—: {fallback_e}")
                    return None
            else:
                print(f"âŒ èªéŸ³åˆæˆéŒ¯èª¤: {e}")
                return None
    
    def start_real_time_translation(self):
        """é–‹å§‹å³æ™‚ç¿»è­¯æ¨¡å¼"""
        if not self.is_voice_cloned:
            print("âŒ è«‹å…ˆå®ŒæˆèªéŸ³å…‹éš†æ­¥é©Ÿï¼")
            return
        
        print("\nğŸš€ å³æ™‚ç¿»è­¯æ¨¡å¼")
        print("-" * 30)
        print(f"ğŸŒ {self.supported_languages[self.source_language]} â†’ {self.supported_languages[self.target_language]}")
        print("ğŸ’¡ ç³»çµ±å°‡æŒçºŒç›£è½æ‚¨çš„èªéŸ³ä¸¦å³æ™‚ç¿»è­¯")
        print("â¹ï¸ æŒ‰ Enter åœæ­¢å³æ™‚ç¿»è­¯")
        
        input("æº–å‚™å¥½å¾ŒæŒ‰ Enter é–‹å§‹å³æ™‚ç¿»è­¯...")
        
        # é‡ç½®ç‹€æ…‹
        self.is_real_time_active = True
        self.should_stop = False
        
        # å•Ÿå‹•å·¥ä½œç·šç¨‹
        threads = []
        
        # éŸ³é »æ•ç²ç·šç¨‹
        capture_thread = threading.Thread(target=self.audio_capture_worker)
        capture_thread.daemon = True
        capture_thread.start()
        threads.append(capture_thread)
        
        # ç¿»è­¯è™•ç†ç·šç¨‹
        translation_thread = threading.Thread(target=self.translation_worker)
        translation_thread.daemon = True
        translation_thread.start()
        threads.append(translation_thread)
        
        # éŸ³é »æ’­æ”¾ç·šç¨‹
        playback_thread = threading.Thread(target=self.playback_worker)
        playback_thread.daemon = True
        playback_thread.start()
        threads.append(playback_thread)
        
        print("\nğŸ”¥ å³æ™‚ç¿»è­¯å·²å•Ÿå‹•ï¼é–‹å§‹èªªè©±å§...")
        print("æŒ‰ Enter åœæ­¢...")
        
        # ç­‰å¾…ç”¨æˆ¶åœæ­¢
        try:
            input()
        except KeyboardInterrupt:
            pass
        
        print("\nâ¹ï¸ æ­£åœ¨åœæ­¢å³æ™‚ç¿»è­¯...")
        
        # åœæ­¢æ‰€æœ‰ç·šç¨‹
        self.should_stop = True
        self.is_real_time_active = False
        
        # ç­‰å¾…ç·šç¨‹çµæŸ
        for thread in threads:
            thread.join(timeout=3)
        
        print("âœ… å³æ™‚ç¿»è­¯å·²åœæ­¢")
    
    def run(self):
        """é‹è¡Œä¸»ç¨‹åº"""
        print("ğŸ¤ æ­¡è¿ä½¿ç”¨å³æ™‚èªéŸ³å…‹éš†ç¿»è­¯ç³»çµ±ï¼")
        
        # ç³»çµ±è¨­ç½®
        if not self.setup_system():
            print("âŒ ç³»çµ±è¨­ç½®å¤±æ•—ï¼Œç¨‹åºé€€å‡º")
            return
        
        print("\n" + "=" * 60)
        print("ğŸ‰ ç³»çµ±è¨­ç½®å®Œæˆï¼")
        print("=" * 60)
        
        while True:
            print("\nğŸ“‹ æ“ä½œé¸é …:")
            print("  c - å…‹éš†èªéŸ³ï¼ˆå¿…é ˆå…ˆå®Œæˆï¼‰")
            print("  enter - é–‹å§‹å³æ™‚ç¿»è­¯")
            print("  q - é€€å‡ºç¨‹åº")
            
            if self.is_voice_cloned:
                print("âœ… èªéŸ³å·²å…‹éš†ï¼Œå¯ä»¥é–‹å§‹å³æ™‚ç¿»è­¯")
            else:
                print("âš ï¸ è«‹å…ˆæŒ‰ 'c' å®ŒæˆèªéŸ³å…‹éš†")
            
            try:
                choice = input("\nè«‹é¸æ“‡æ“ä½œ: ").strip().lower()
                
                if choice == 'q':
                    print("ğŸ‘‹ å†è¦‹ï¼")
                    break
                elif choice == 'c':
                    if self.clone_voice_step():
                        print("âœ… èªéŸ³å…‹éš†å®Œæˆï¼Œç¾åœ¨å¯ä»¥é–‹å§‹å³æ™‚ç¿»è­¯äº†ï¼")
                    else:
                        print("âŒ èªéŸ³å…‹éš†å¤±æ•—ï¼Œè«‹é‡è©¦")
                elif choice == '' or choice == 'enter':
                    self.start_real_time_translation()
                else:
                    print("âŒ ç„¡æ•ˆé¸é …ï¼Œè«‹é‡æ–°é¸æ“‡")
                    
            except KeyboardInterrupt:
                print("\nğŸ‘‹ ç¨‹åºè¢«ä¸­æ–·ï¼Œå†è¦‹ï¼")
                break
            except Exception as e:
                print(f"âŒ ç™¼ç”ŸéŒ¯èª¤: {e}")

# ä¸»ç¨‹åºå…¥å£
if __name__ == "__main__":
    system = RealTimeVoiceTranslationSystem()
    system.run()