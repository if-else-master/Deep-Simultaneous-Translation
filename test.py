import pyaudio
import wave
import threading
import time
import io
import google.generativeai as genai
from TTS.tts.configs.xtts_config import XttsConfig
from TTS.tts.models.xtts import Xtts
import torch
import scipy.io.wavfile
import numpy as np
import pygame
import tempfile
import os
import shutil
import queue
from collections import deque

class VoiceTranslationSystem:
    def __init__(self, gemini_api_key):
        # åˆå§‹åŒ– Gemini API
        genai.configure(api_key=gemini_api_key)
        self.model = genai.GenerativeModel('gemini-2.0-flash-exp')
        
        # åˆå§‹åŒ– XTTS æ¨¡å‹
        print("æ­£åœ¨è¼‰å…¥ XTTS æ¨¡å‹...")
        config = XttsConfig()
        config.load_json("XTTS-v2/config.json")
        self.xtts_model = Xtts.init_from_config(config)
        self.xtts_model.load_checkpoint(config, checkpoint_dir="XTTS-v2/", eval=True)
        
        if torch.cuda.is_available():
            self.xtts_model.cuda()
            print("ä½¿ç”¨ GPU åŠ é€Ÿ")
        
        self.config = config
        
        # éŸ³é »åƒæ•¸
        self.chunk = 1024
        self.format = pyaudio.paInt16
        self.channels = 1
        self.rate = 16000  # é™ä½æ¡æ¨£ç‡ä»¥æé«˜è™•ç†æ•ˆç‡
        
        # åˆå§‹åŒ– pygame ç”¨æ–¼æ’­æ”¾éŸ³é »
        pygame.mixer.init()
        
        # æŒçºŒéŒ„éŸ³æ§åˆ¶
        self.is_continuous_recording = False
        self.should_stop = False
        self.audio_queue = queue.Queue()
        self.processing_queue = queue.Queue()
        
        # èªéŸ³æ´»å‹•æª¢æ¸¬åƒæ•¸
        self.silence_threshold = 500  # éŸ³é‡é–¾å€¼
        self.silence_duration = 1.5   # éœéŸ³æŒçºŒæ™‚é–“ï¼ˆç§’ï¼‰
        self.min_speech_duration = 0.5  # æœ€å°èªéŸ³æŒçºŒæ™‚é–“ï¼ˆç§’ï¼‰
        
        # èªéŸ³å…‹éš†ç›¸é—œ
        self.cloned_voice_path = None
        self.is_voice_cloned = False
        
        # éŸ³é »ç·©è¡å€
        self.audio_buffer = deque(maxlen=int(self.rate * 10))  # 10ç§’ç·©è¡å€
        self.current_segment = []
        self.last_speech_time = 0
        self.is_speech_detected = False
        
        print("ç³»çµ±åˆå§‹åŒ–å®Œæˆï¼")
    
    def calculate_rms(self, audio_data):
        """è¨ˆç®—éŸ³é »çš„RMSå€¼ç”¨æ–¼èªéŸ³æ´»å‹•æª¢æ¸¬"""
        audio_np = np.frombuffer(audio_data, dtype=np.int16)
        return np.sqrt(np.mean(audio_np**2))
    
    def detect_voice_activity(self, audio_data):
        """èªéŸ³æ´»å‹•æª¢æ¸¬"""
        rms = self.calculate_rms(audio_data)
        current_time = time.time()
        
        if rms > self.silence_threshold:
            # æª¢æ¸¬åˆ°èªéŸ³
            if not self.is_speech_detected:
                self.is_speech_detected = True
                print("ğŸ¤ æª¢æ¸¬åˆ°èªéŸ³é–‹å§‹")
            self.last_speech_time = current_time
            return True
        else:
            # éœéŸ³
            if self.is_speech_detected:
                silence_duration = current_time - self.last_speech_time
                if silence_duration >= self.silence_duration:
                    # éœéŸ³æŒçºŒæ™‚é–“è¶³å¤ ï¼Œèªç‚ºèªéŸ³çµæŸ
                    self.is_speech_detected = False
                    return False
            return self.is_speech_detected
    
    def continuous_audio_capture(self):
        """æŒçºŒéŸ³é »æ•ç²ç·šç¨‹"""
        audio = pyaudio.PyAudio()
        stream = audio.open(format=self.format,
                          channels=self.channels,
                          rate=self.rate,
                          input=True,
                          frames_per_buffer=self.chunk)
        
        print("ğŸ¤ é–‹å§‹æŒçºŒèªéŸ³ç›£è½...")
        
        while self.is_continuous_recording:
            try:
                data = stream.read(self.chunk, exception_on_overflow=False)
                self.audio_buffer.extend(np.frombuffer(data, dtype=np.int16))
                
                # èªéŸ³æ´»å‹•æª¢æ¸¬
                is_speech = self.detect_voice_activity(data)
                
                if is_speech:
                    # æ­£åœ¨èªªè©±ï¼Œæ”¶é›†éŸ³é »
                    self.current_segment.extend(np.frombuffer(data, dtype=np.int16))
                elif self.current_segment and len(self.current_segment) > int(self.rate * self.min_speech_duration):
                    # èªéŸ³çµæŸä¸”é•·åº¦è¶³å¤ ï¼Œç™¼é€è™•ç†
                    print("ğŸ“ æª¢æ¸¬åˆ°èªéŸ³çµæŸï¼Œç™¼é€è™•ç†...")
                    segment_audio = np.array(self.current_segment, dtype=np.int16)
                    self.processing_queue.put(segment_audio)
                    self.current_segment = []
                
                # æª¢æŸ¥æ˜¯å¦éœ€è¦åœæ­¢
                if self.should_stop:
                    break
                    
            except Exception as e:
                print(f"âŒ éŸ³é »æ•ç²éŒ¯èª¤: {e}")
                break
        
        stream.stop_stream()
        stream.close()
        audio.terminate()
        print("ğŸ¤ éŸ³é »æ•ç²å·²åœæ­¢")
    
    def save_audio_segment(self, audio_data, suffix='_segment'):
        """å°‡éŸ³é »æ®µä¿å­˜åˆ°è‡¨æ™‚æ–‡ä»¶"""
        temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=f'{suffix}.wav')
        
        # ç¢ºä¿éŸ³é »æ•¸æ“šæ˜¯æ­£ç¢ºçš„æ ¼å¼
        if isinstance(audio_data, np.ndarray):
            audio_data = audio_data.astype(np.int16)
        
        scipy.io.wavfile.write(temp_file.name, self.rate, audio_data)
        return temp_file.name
    
    def clone_voice_from_segment(self, audio_file_path):
        """å¾éŸ³é »æ®µå…‹éš†èªéŸ³"""
        try:
            if self.is_voice_cloned:
                return self.cloned_voice_path
            
            print("ğŸ­ æ­£åœ¨é€²è¡Œé¦–æ¬¡èªéŸ³å…‹éš†...")
            
            # å‰µå»ºå…‹éš†èªéŸ³å­˜å„²ç›®éŒ„
            if not os.path.exists("cloned_voices"):
                os.makedirs("cloned_voices")
            
            # å°‡éŸ³é »æ®µè¤‡è£½ä½œç‚ºèªéŸ³å…‹éš†åƒè€ƒ
            cloned_voice_filename = f"cloned_voices/cloned_voice_{int(time.time())}.wav"
            shutil.copy2(audio_file_path, cloned_voice_filename)
            
            self.cloned_voice_path = cloned_voice_filename
            self.is_voice_cloned = True
            print(f"âœ… èªéŸ³å…‹éš†å®Œæˆï¼Œåƒè€ƒæ–‡ä»¶: {cloned_voice_filename}")
            
            return cloned_voice_filename
            
        except Exception as e:
            print(f"âŒ èªéŸ³å…‹éš†éç¨‹ç™¼ç”ŸéŒ¯èª¤: {e}")
            return None
    
    def transcribe_and_translate(self, audio_file_path, target_language="en"):
        """ä½¿ç”¨ Gemini é€²è¡ŒèªéŸ³è½‰æ–‡å­—å’Œç¿»è­¯"""
        try:
            print("ğŸ¤– æ­£åœ¨é€²è¡ŒèªéŸ³è­˜åˆ¥å’Œç¿»è­¯...")
            
            # ä¸Šå‚³éŸ³é »æ–‡ä»¶
            audio_file = genai.upload_file(path=audio_file_path)
            
            # æ ¹æ“šç›®æ¨™èªè¨€è¨­å®šæç¤ºè©
            if target_language.lower() == "en":
                prompt = "è«‹å°‡é€™æ®µéŸ³é »ä¸­çš„èªéŸ³å…§å®¹è½‰æ›ç‚ºè‹±æ–‡æ–‡å­—ï¼Œå¦‚æœåŸæœ¬å°±æ˜¯è‹±æ–‡å°±ç›´æ¥è½‰éŒ„ï¼Œå¦‚æœæ˜¯å…¶ä»–èªè¨€è«‹ç¿»è­¯æˆè‹±æ–‡ã€‚åªå›å‚³æœ€çµ‚çš„è‹±æ–‡æ–‡å­—å…§å®¹ï¼Œä¸è¦åŒ…å«å…¶ä»–èªªæ˜ã€‚"
            elif target_language.lower() == "zh":
                prompt = "è«‹å°‡é€™æ®µéŸ³é »ä¸­çš„èªéŸ³å…§å®¹è½‰æ›ç‚ºç¹é«”ä¸­æ–‡æ–‡å­—ï¼Œå¦‚æœåŸæœ¬å°±æ˜¯ä¸­æ–‡å°±ç›´æ¥è½‰éŒ„ï¼Œå¦‚æœæ˜¯å…¶ä»–èªè¨€è«‹ç¿»è­¯æˆç¹é«”ä¸­æ–‡ã€‚åªå›å‚³æœ€çµ‚çš„ç¹é«”ä¸­æ–‡æ–‡å­—å…§å®¹ï¼Œä¸è¦åŒ…å«å…¶ä»–èªªæ˜ã€‚"
            else:
                prompt = f"è«‹å°‡é€™æ®µéŸ³é »ä¸­çš„èªéŸ³å…§å®¹è½‰æ›ç‚º{target_language}æ–‡å­—ï¼Œå¦‚æœéœ€è¦ç¿»è­¯è«‹ç¿»è­¯æˆ{target_language}ã€‚åªå›å‚³æœ€çµ‚çš„æ–‡å­—å…§å®¹ï¼Œä¸è¦åŒ…å«å…¶ä»–èªªæ˜ã€‚"
            
            # ç™¼é€è«‹æ±‚åˆ° Gemini
            response = self.model.generate_content([audio_file, prompt])
            
            # æ¸…ç†ä¸Šå‚³çš„æ–‡ä»¶
            genai.delete_file(audio_file.name)
            
            translated_text = response.text.strip()
            print(f"ğŸ“ ç¿»è­¯çµæœ: {translated_text}")
            
            return translated_text
            
        except Exception as e:
            print(f"âŒ ç¿»è­¯éç¨‹ç™¼ç”ŸéŒ¯èª¤: {e}")
            return None
    
    def synthesize_speech_with_cloned_voice(self, text, output_file=None):
        """ä½¿ç”¨å…‹éš†çš„èªéŸ³åˆæˆèªéŸ³"""
        try:
            if not output_file:
                output_file = f"output_speech_{int(time.time())}.wav"
            
            print("ğŸ”Š æ­£åœ¨ä½¿ç”¨å…‹éš†èªéŸ³åˆæˆèªéŸ³...")
            
            if not self.cloned_voice_path or not os.path.exists(self.cloned_voice_path):
                print("âŒ æ²’æœ‰å¯ç”¨çš„å…‹éš†èªéŸ³")
                return None
            
            # æª¢æ¸¬èªè¨€
            has_chinese = any('\u4e00' <= char <= '\u9fff' for char in text)
            language = "zh-cn" if has_chinese else "en"
            
            print(f"ğŸŒ æª¢æ¸¬åˆ°èªè¨€: {'ä¸­æ–‡' if language == 'zh-cn' else 'è‹±æ–‡'}")
            
            outputs = self.xtts_model.synthesize(
                text,
                self.config,
                speaker_wav=self.cloned_voice_path,
                gpt_cond_len=3,
                language=language,
            )
            
            # ä¿å­˜éŸ³é »
            scipy.io.wavfile.write(output_file, rate=24000, data=outputs["wav"])
            print(f"âœ… èªéŸ³åˆæˆå®Œæˆ")
            
            return output_file
            
        except AttributeError as e:
            if "'GPT2InferenceModel' object has no attribute 'generate'" in str(e):
                print("âŒ éŒ¯èª¤ï¼štransformersåº«ç‰ˆæœ¬éé«˜ï¼Œè«‹é™ç´šåˆ°4.49.0ç‰ˆæœ¬")
                print("è«‹é‹è¡Œ: pip install transformers==4.49.0")
                return None
            else:
                raise e
        except Exception as e:
            print(f"âŒ èªéŸ³åˆæˆç™¼ç”ŸéŒ¯èª¤: {e}")
            return None
    
    def play_audio(self, audio_file):
        """æ’­æ”¾éŸ³é »æ–‡ä»¶"""
        try:
            pygame.mixer.music.load(audio_file)
            pygame.mixer.music.play()
            
            # ç­‰å¾…æ’­æ”¾å®Œæˆ
            while pygame.mixer.music.get_busy():
                time.sleep(0.1)
                
        except Exception as e:
            print(f"âŒ æ’­æ”¾éŸ³é »æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
    
    def process_audio_segment(self, audio_segment, target_language="en"):
        """è™•ç†å–®å€‹éŸ³é »æ®µ"""
        temp_audio_file = None
        output_file = None
        
        try:
            # ä¿å­˜éŸ³é »æ®µåˆ°è‡¨æ™‚æ–‡ä»¶
            temp_audio_file = self.save_audio_segment(audio_segment)
            
            # å¦‚æœé‚„æ²’æœ‰å…‹éš†èªéŸ³ï¼Œå…ˆé€²è¡Œå…‹éš†
            if not self.is_voice_cloned:
                self.clone_voice_from_segment(temp_audio_file)
            
            # ç¿»è­¯éŸ³é »å…§å®¹
            translated_text = self.transcribe_and_translate(temp_audio_file, target_language)
            
            if translated_text and translated_text.strip():
                # ä½¿ç”¨å…‹éš†èªéŸ³åˆæˆç¿»è­¯å¾Œçš„å…§å®¹
                output_file = self.synthesize_speech_with_cloned_voice(translated_text)
                
                if output_file:
                    # æ’­æ”¾çµæœ
                    self.play_audio(output_file)
                    print("ğŸ‰ èªéŸ³ç‰‡æ®µè™•ç†å®Œæˆ\n" + "="*50)
            else:
                print("âš ï¸ æ²’æœ‰æª¢æ¸¬åˆ°æœ‰æ•ˆçš„èªéŸ³å…§å®¹")
            
        except Exception as e:
            print(f"âŒ è™•ç†éŸ³é »æ®µæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        
        finally:
            # æ¸…ç†è‡¨æ™‚æ–‡ä»¶
            for file_path in [temp_audio_file, output_file]:
                if file_path and os.path.exists(file_path):
                    try:
                        os.unlink(file_path)
                    except:
                        pass
    
    def audio_processing_worker(self, target_language="en"):
        """éŸ³é »è™•ç†å·¥ä½œç·šç¨‹"""
        print("ğŸ”„ éŸ³é »è™•ç†ç·šç¨‹å·²å•Ÿå‹•")
        
        while self.is_continuous_recording or not self.processing_queue.empty():
            try:
                # ç²å–å¾…è™•ç†çš„éŸ³é »æ®µ
                audio_segment = self.processing_queue.get(timeout=1)
                print(f"\n{'='*50}")
                print("ğŸ¯ é–‹å§‹è™•ç†æ–°çš„èªéŸ³ç‰‡æ®µ...")
                
                # è™•ç†éŸ³é »æ®µ
                self.process_audio_segment(audio_segment, target_language)
                
                self.processing_queue.task_done()
                
            except queue.Empty:
                continue
            except Exception as e:
                print(f"âŒ è™•ç†ç·šç¨‹éŒ¯èª¤: {e}")
        
        print("ğŸ”„ éŸ³é »è™•ç†ç·šç¨‹å·²åœæ­¢")
    
    def start_continuous_translation(self, target_language="en"):
        """é–‹å§‹æŒçºŒç¿»è­¯æ¨¡å¼"""
        print("ğŸš€ å•Ÿå‹•æ·±åº¦åŒæ­¥ç¿»è­¯æ¨¡å¼ï¼")
        print("ğŸ“¢ ç³»çµ±å°‡æŒçºŒç›£è½ä½ çš„èªéŸ³ä¸¦å¯¦æ™‚ç¿»è­¯")
        print("ğŸ’¡ èªªè©±å¾Œåœé “1.5ç§’ï¼Œç³»çµ±æœƒè‡ªå‹•è™•ç†ä¸¦æ’­æ”¾ç¿»è­¯")
        print("â¹ï¸ è¼¸å…¥ 'stop' çµæŸç¿»è­¯æ¨¡å¼")
        print(f"ğŸŒ ç›®æ¨™èªè¨€: {'è‹±æ–‡' if target_language == 'en' else 'ä¸­æ–‡'}")
        
        # ç­‰å¾…ç”¨æˆ¶æŒ‰ Enter é–‹å§‹
        input("\næŒ‰ Enter é–‹å§‹æ·±åº¦åŒæ­¥ç¿»è­¯...")
        
        # é‡ç½®ç‹€æ…‹
        self.should_stop = False
        self.is_continuous_recording = True
        self.is_voice_cloned = False
        self.cloned_voice_path = None
        
        # å•Ÿå‹•éŸ³é »æ•ç²ç·šç¨‹
        capture_thread = threading.Thread(target=self.continuous_audio_capture)
        capture_thread.daemon = True
        capture_thread.start()
        
        # å•Ÿå‹•éŸ³é »è™•ç†ç·šç¨‹
        processing_thread = threading.Thread(target=self.audio_processing_worker, args=(target_language,))
        processing_thread.daemon = True
        processing_thread.start()
        
        print("\nğŸ”¥ æ·±åº¦åŒæ­¥ç¿»è­¯å·²å•Ÿå‹•ï¼é–‹å§‹èªªè©±å§...")
        
        # ç­‰å¾…ç”¨æˆ¶è¼¸å…¥ stop
        while True:
            try:
                user_input = input().strip().lower()
                if user_input == 'stop':
                    print("\nâ¹ï¸ æ­£åœ¨åœæ­¢æ·±åº¦åŒæ­¥ç¿»è­¯...")
                    break
            except KeyboardInterrupt:
                print("\nâ¹ï¸ ç”¨æˆ¶ä¸­æ–·ï¼Œæ­£åœ¨åœæ­¢...")
                break
        
        # åœæ­¢æ‰€æœ‰ç·šç¨‹
        self.should_stop = True
        self.is_continuous_recording = False
        
        # ç­‰å¾…ç·šç¨‹çµæŸ
        capture_thread.join(timeout=2)
        processing_thread.join(timeout=5)
        
        print("âœ… æ·±åº¦åŒæ­¥ç¿»è­¯å·²åœæ­¢")
    
    def run_translation_loop(self, target_language="en"):
        """é‹è¡Œç¿»è­¯å¾ªç’°"""
        print("ğŸš€ èªéŸ³å…‹éš†ç¿»è­¯ç³»çµ±å•Ÿå‹•ï¼")
        print("\n=== ç³»çµ±æ¨¡å¼ ===")
        print("1. ğŸ”¥ æ·±åº¦åŒæ­¥ç¿»è­¯ - æŒçºŒç›£è½ä¸¦å¯¦æ™‚ç¿»è­¯ (æ¨è–¦)")
        print("2. ğŸ¤ å‚³çµ±æ¨¡å¼ - æ‰‹å‹•éŒ„éŸ³ç¿»è­¯")
        
        print("\n=== æŒ‡ä»¤èªªæ˜ ===")
        print("- è¼¸å…¥ 'continuous' æˆ– 'c' é–‹å§‹æ·±åº¦åŒæ­¥ç¿»è­¯")
        print("- è¼¸å…¥ 'start' æˆ– 's' é–‹å§‹å‚³çµ±æ¨¡å¼")
        print("- è¼¸å…¥ 'lang en' è¨­å®šç¿»è­¯ç‚ºè‹±æ–‡")
        print("- è¼¸å…¥ 'lang zh' è¨­å®šç¿»è­¯ç‚ºä¸­æ–‡")
        print("- è¼¸å…¥ 'clean' æ¸…ç†æ‰€æœ‰å…‹éš†èªéŸ³")
        print("- è¼¸å…¥ 'quit' æˆ– 'q' é€€å‡ºç¨‹å¼")
        
        print(f"\nç›®å‰ç¿»è­¯èªè¨€: {'è‹±æ–‡' if target_language == 'en' else 'ä¸­æ–‡'}")
        
        while True:
            try:
                command = input("\nè«‹è¼¸å…¥æŒ‡ä»¤: ").strip().lower()
                
                if command in ['quit', 'q']:
                    print("ğŸ‘‹ å†è¦‹ï¼")
                    break
                
                elif command.startswith('lang '):
                    new_lang = command.split(' ')[1]
                    if new_lang in ['en', 'zh']:
                        target_language = new_lang
                        print(f"âœ… ç¿»è­¯èªè¨€å·²è¨­å®šç‚º: {'è‹±æ–‡' if target_language == 'en' else 'ä¸­æ–‡'}")
                    else:
                        print("âŒ æ”¯æ´çš„èªè¨€: en (è‹±æ–‡), zh (ä¸­æ–‡)")
                
                elif command == 'clean':
                    self.clean_cloned_voices()
                
                elif command in ['continuous', 'c']:
                    self.start_continuous_translation(target_language)
                
                elif command in ['start', 's']:
                    print("\nğŸ¬ é–‹å§‹å‚³çµ±èªéŸ³ç¿»è­¯æµç¨‹...")
                    success = self.process_voice_translation(target_language)
                    
                    if success:
                        print("\nğŸ‰ èªéŸ³ç¿»è­¯æµç¨‹å®Œæˆï¼")
                    else:
                        print("\nâŒ æµç¨‹åŸ·è¡Œå¤±æ•—ï¼Œè«‹é‡è©¦")
                
                else:
                    print("âŒ æœªçŸ¥æŒ‡ä»¤ï¼Œè«‹è¼¸å…¥ 'continuous' é–‹å§‹æ·±åº¦åŒæ­¥ç¿»è­¯æˆ– 'quit' é€€å‡º")
                    
            except KeyboardInterrupt:
                print("\nğŸ‘‹ ç¨‹å¼è¢«ä¸­æ–·ï¼Œå†è¦‹ï¼")
                break
            except Exception as e:
                print(f"âŒ ç™¼ç”ŸéŒ¯èª¤: {e}")

    def start_recording(self):
        """é–‹å§‹éŒ„éŸ³"""
        self.is_recording = True
        self.audio_frames = []
        
        audio = pyaudio.PyAudio()
        stream = audio.open(format=self.format,
                          channels=self.channels,
                          rate=self.rate,
                          input=True,
                          frames_per_buffer=self.chunk)
        
        print("ğŸ¤ éŒ„éŸ³ä¸­... æŒ‰ Enter åœæ­¢éŒ„éŸ³")
        
        while self.is_recording:
            data = stream.read(self.chunk)
            self.audio_frames.append(data)
        
        print("ğŸ“ éŒ„éŸ³çµæŸ")
        stream.stop_stream()
        stream.close()
        audio.terminate()
    
    def stop_recording(self):
        """åœæ­¢éŒ„éŸ³"""
        self.is_recording = False
    
    def save_audio_to_temp(self, suffix='_original'):
        """å°‡éŒ„éŸ³ä¿å­˜åˆ°è‡¨æ™‚æ–‡ä»¶"""
        if not self.audio_frames:
            return None
        
        # å‰µå»ºè‡¨æ™‚æ–‡ä»¶
        temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=f'{suffix}.wav')
        
        audio = pyaudio.PyAudio()
        wf = wave.open(temp_file.name, 'wb')
        wf.setnchannels(self.channels)
        wf.setsampwidth(audio.get_sample_size(self.format))
        wf.setframerate(self.rate)
        wf.writeframes(b''.join(self.audio_frames))
        wf.close()
        audio.terminate()
        
        return temp_file.name
    
    def clone_voice(self, audio_file_path):
        """å…‹éš†èªéŸ³ - å°‡éŒ„éŸ³æ–‡ä»¶è¤‡è£½ç‚ºèªéŸ³åƒè€ƒ"""
        try:
            print("ğŸ­ æ­£åœ¨å…‹éš†èªéŸ³...")
            
            # å‰µå»ºå…‹éš†èªéŸ³å­˜å„²ç›®éŒ„
            if not os.path.exists("cloned_voices"):
                os.makedirs("cloned_voices")
            
            # å°‡åŸå§‹éŒ„éŸ³è¤‡è£½ä½œç‚ºèªéŸ³å…‹éš†åƒè€ƒ
            cloned_voice_filename = f"cloned_voices/cloned_voice_{int(time.time())}.wav"
            shutil.copy2(audio_file_path, cloned_voice_filename)
            
            self.cloned_voice_path = cloned_voice_filename
            print(f"âœ… èªéŸ³å…‹éš†å®Œæˆï¼Œåƒè€ƒæ–‡ä»¶: {cloned_voice_filename}")
            
            return cloned_voice_filename
            
        except Exception as e:
            print(f"âŒ èªéŸ³å…‹éš†éç¨‹ç™¼ç”ŸéŒ¯èª¤: {e}")
            return None
    
    def process_voice_translation(self, target_language="en"):
        """å®Œæ•´çš„èªéŸ³ç¿»è­¯æµç¨‹ï¼šéŒ„éŸ³ â†’ å…‹éš†èªéŸ³ â†’ ç¿»è­¯ â†’ åˆæˆ"""
        # åˆå§‹åŒ–éŒ„éŸ³è®Šé‡
        self.is_recording = True
        self.audio_frames = []
        
        # é–‹å§‹éŒ„éŸ³
        recording_thread = threading.Thread(target=self.start_recording)
        recording_thread.start()
        
        # ç­‰å¾…ç”¨æˆ¶æŒ‰ Enter åœæ­¢éŒ„éŸ³
        input()
        self.stop_recording()
        recording_thread.join()
        
        # ä¿å­˜éŒ„éŸ³åˆ°è‡¨æ™‚æ–‡ä»¶
        temp_audio_file = self.save_audio_to_temp()
        
        if not temp_audio_file:
            print("âŒ æ²’æœ‰éŒ„éŸ³æ•¸æ“š")
            return False
        
        try:
            # æ­¥é©Ÿ1: å…‹éš†èªéŸ³
            print("\n=== æ­¥é©Ÿ 1: èªéŸ³å…‹éš† ===")
            cloned_voice_file = self.clone_voice(temp_audio_file)
            
            if not cloned_voice_file:
                return False
            
            # æ­¥é©Ÿ2: ç¿»è­¯éŸ³é »å…§å®¹
            print("\n=== æ­¥é©Ÿ 2: èªéŸ³ç¿»è­¯ ===")
            translated_text = self.transcribe_and_translate(temp_audio_file, target_language)
            
            if not translated_text:
                return False
            
            # æ­¥é©Ÿ3: ä½¿ç”¨å…‹éš†èªéŸ³åˆæˆç¿»è­¯å¾Œçš„å…§å®¹
            print("\n=== æ­¥é©Ÿ 3: èªéŸ³åˆæˆ ===")
            output_file = self.synthesize_speech_with_cloned_voice(translated_text)
            
            if not output_file:
                return False
            
            # æ­¥é©Ÿ4: æ’­æ”¾çµæœ
            print("\n=== æ­¥é©Ÿ 4: æ’­æ”¾çµæœ ===")
            self.play_audio(output_file)
            
            return True
            
        finally:
            # æ¸…ç†è‡¨æ™‚æ–‡ä»¶
            try:
                if temp_audio_file and os.path.exists(temp_audio_file):
                    os.unlink(temp_audio_file)
            except:
                pass
    
    def show_cloned_voices(self):
        """é¡¯ç¤ºå·²å…‹éš†çš„èªéŸ³æ–‡ä»¶"""
        if not os.path.exists("cloned_voices"):
            print("ğŸ“ é‚„æ²’æœ‰å…‹éš†çš„èªéŸ³æ–‡ä»¶")
            return
        
        voices = [f for f in os.listdir("cloned_voices") if f.endswith('.wav')]
        if not voices:
            print("ğŸ“ é‚„æ²’æœ‰å…‹éš†çš„èªéŸ³æ–‡ä»¶")
            return
        
        print("ğŸ“ å·²å…‹éš†çš„èªéŸ³æ–‡ä»¶:")
        for i, voice in enumerate(voices, 1):
            print(f"  {i}. {voice}")
    
    def clean_cloned_voices(self):
        """æ¸…ç†æ‰€æœ‰å…‹éš†çš„èªéŸ³æ–‡ä»¶"""
        if os.path.exists("cloned_voices"):
            try:
                shutil.rmtree("cloned_voices")
                print("ğŸ—‘ï¸ å·²æ¸…ç†æ‰€æœ‰å…‹éš†çš„èªéŸ³æ–‡ä»¶")
                self.cloned_voice_path = None
                self.is_voice_cloned = False
            except Exception as e:
                print(f"âŒ æ¸…ç†å¤±æ•—: {e}")
        else:
            print("ğŸ“ æ²’æœ‰éœ€è¦æ¸…ç†çš„æ–‡ä»¶")

# ä½¿ç”¨ç¯„ä¾‹
if __name__ == "__main__":
    # è«‹æ›¿æ›ç‚ºä½ çš„ Gemini API Key
    GEMINI_API_KEY = "########################"
    
    # åˆå§‹åŒ–ç³»çµ±ï¼ˆä¸éœ€è¦é è¨­çš„åƒè€ƒèªéŸ³ï¼Œå› ç‚ºæœƒç”¨å…‹éš†çš„èªéŸ³ï¼‰
    system = VoiceTranslationSystem(gemini_api_key=GEMINI_API_KEY)
    
    # é‹è¡Œç¿»è­¯å¾ªç’°ï¼Œé è¨­ç¿»è­¯ç‚ºè‹±æ–‡
    system.run_translation_loop(target_language="en")